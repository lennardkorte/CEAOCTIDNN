
\chapter{Conclusion}

In this work \acrshort{dl} models were developed that considered the detailed use of different \acrshort{da} techniques specifically for \acrshort{ivoct} data sets for the first time. The pipeline contained a data loader transforming the \glspl{b-scan} online with different techniques substituting the effect of actual augmentation. The iterative development of different models with their automatic performance evaluation helped to find valuable transformations for building an effective augmentation strategy. In contrast to previous investigations, we presented a variety of diverse methods that proved the concept of augmenting medical image data for training \acrshortpl{nn}. The application of the techniques was demonstrated on the implemented pipeline utilizing \acrshort{resnet}-18 in its core. The augmentation of medical \acrshort{ivoct} data with various artefacts demonstrated the performance boost that can be achieved by building an appropriate strategy combining multiple techniques. The trained models therefore come with measurable performance enhancement that could aid in developing a system providing automatic decision support and analysis of the in vivo vascular anatomy. It was shown during augmentation experiments that the different techniques provide varying enhancement degrees of model performance. \Acrshort{cv} allowed the comparison of different runs and enabled us to deal with strong fluctuation and different behavior of each fold. The enhancement estimation based on individual techniques was often volatile and significant distinctions were only measurable when combined for training a single model. Techniques that were found to have positive effect on the models classification performance were compared and proposed for further investigation. Hereafter, domain specific training strategies may be build for future fine tuned training. It was shown that the models performance is determined by the extent to which relevant information and features of the original medical images are preserved in the augmented training sets. Overall, we find that a model trained with data augmented by the discussed techniques, e.g. affine transformations, may boost the performance by 0.05 in \acrfull{mcc} and 0.03 in \acrfull{bacc}. Less effective transformations such as contrast jittering may deteriorate scores significantly by more than ten percent. Obtained results proved the immense impact and therefore the relevance of \acrshort{da} when building deep learning models with the use of small \acrshort{ivoct} data sets. The implemented pipeline and transformations may now serve as a basis for future investigations into \acrshort{da} and development with further fine-tuning in training with predictive performance satisfactory for clinical use.



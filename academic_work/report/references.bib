% This file was created with Citavi 6.11.0.0

@article{.,
 title = {2005{\_}Chapter{\_}Wellengleichungen},
 file = {2005{\_}Chapter{\_}Wellengleichungen:Attachments/2005{\_}Chapter{\_}Wellengleichungen.pdf:application/pdf}
}


@proceedings{.2003,
 year = {2003},
 title = {Icdar}
}


@proceedings{.2003b,
 year = {2003},
 title = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings},
 publisher = {{IEEE Comput. Soc}},
 isbn = {0-7695-1960-1}
}


@proceedings{.2013,
 year = {2013}
}


@book{.2015,
 year = {2015},
 title = {Multiple Sklerose},
 publisher = {Elsevier},
 isbn = {9783437220838}
}


@proceedings{.2015b,
 year = {2015},
 title = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}


@proceedings{.2016,
 year = {2016},
 title = {2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)},
 publisher = {IEEE},
 isbn = {978-1-5090-2896-2}
}


@proceedings{.2017,
 year = {2017},
 title = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 publisher = {IEEE},
 isbn = {978-1-5386-0457-1},
 doi = {10.1109/CVPR35066.2017}
}


@proceedings{.2017b,
 year = {2017},
 title = {2017 International Conference on Engineering and Technology (ICET)},
 publisher = {IEEE},
 isbn = {978-1-5386-1949-0},
 doi = {10.1109/ICET42298.2017}
}


@proceedings{.2018,
 year = {2018},
 title = {2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)},
 publisher = {IEEE},
 isbn = {978-1-5386-3636-7}
}


@proceedings{.2018b,
 year = {2018},
 title = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
 publisher = {IEEE},
 isbn = {978-1-5386-6420-9}
}


@proceedings{.2018c,
 year = {2018}
}


@proceedings{.2019,
 year = {2019},
 title = {2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI)}
}


@proceedings{.2020,
 year = {2020},
 title = {2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)}
}


@proceedings{.2020b,
 year = {2020},
 title = {2020 7th International Conference on Computing for Sustainable Global Development (INDIACom)}
}


@book{.b,
 title = {Proceedings of the Fourteenth Internal Conference on Artificial Intelligence and Statistics}
}


@book{.c,
 title = {Proceedings of the Fourteenth Internal Conference on Artificial Intelligence and Statistics}
}


@book{.d,
 title = {Proceedings of the Fourteenth Internal Conference on Artificial Intelligence and Statistics}
}


@article{Abdolmanafi.2017,
 abstract = {Kawasaki disease (KD) is an acute childhood disease complicated by coronary artery aneurysms, intima thickening, thrombi, stenosis, lamellar calcifications, and disappearance of the media border. Automatic classification of the coronary artery layers (intima, media, and scar features) is important for analyzing optical coherence tomography (OCT) images recorded in pediatric patients. OCT has been known as an intracoronary imaging modality using near-infrared light which has recently been used to image the inner coronary artery tissues of pediatric patients, providing high spatial resolution (ranging from 10 to 20 \textgreek{m}m). This study aims to develop a robust and fully automated tissue classification method by using the convolutional neural networks (CNNs) as feature extractor and comparing the predictions of three state-of-the-art classifiers, CNN, random forest (RF), and support vector machine (SVM). The results show the robustness of CNN as the feature extractor and random forest as the classifier with classification rate up to 96{\%}, especially to characterize the second layer of coronary arteries (media), which is a very thin layer and it is challenging to be recognized and specified from other tissues.},
 author = {Abdolmanafi, Atefeh and Duong, Luc and Dahdah, Nagib and Cheriet, Farida},
 year = {2017},
 title = {Deep feature learning for automatic tissue classification of coronary artery using optical coherence tomography},
 pages = {1203--1220},
 volume = {8},
 issn = {2156-7085},
 journal = {Biomedical optics express},
 doi = {10.1364/BOE.8.001203},
 file = {boe-8-2-1203:Attachments/boe-8-2-1203.pdf:application/pdf}
}


@article{AdamM.Zysk.2007,
 author = {Zysk, Adam M. and Nguyen, Freddy T. Oldenburg and {Amy L.} and {Daniel L. Marks} and {Stephen A. Boppart M.D.}},
 year = {2007},
 title = {Optical coherence tomography: a review of clinical development from bench to bedside},
 keywords = {Biomedical optics;clinical imaging;clinical translation;Diagnostics;Imaging systems;In vivo imaging;optical coherence tomography;Standards development;Tissue optics;Tissues;Tumors;Visualization},
 pages = {1--21},
 volume = {12},
 journal = {Journal of Biomedical Optics},
 doi = {10.1117/1.2793736},
 file = {Adam M Zysk, Freddy T Nguyen et al 2007 - Optical coherence tomography:Attachments/Adam M Zysk, Freddy T Nguyen et al 2007 - Optical coherence tomography.pdf:application/pdf}
}


@article{Albawi.2017,
 abstract = {2017 International Conference on Engineering and Technology (ICET);2017; ; ;10.1109/ICEngTechnol.2017.8308186},
 author = {Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
 year = {2017},
 title = {Understanding of a convolutional neural network},
 keywords = {artificial neural networks;computer vision;Convolutional neural networks;deep learning;Image recognition;Machine Learning},
 pages = {1--6},
 journal = {International Conference on Engineering},
 doi = {10.1109/ICEngTechnol.2017.8308186},
 file = {Understanding{\_}of{\_}a{\_}convolutional{\_}neural{\_}network:Attachments/Understanding{\_}of{\_}a{\_}convolutional{\_}neural{\_}network.pdf:application/pdf}
}


@misc{Antoniou.11122017,
 abstract = {Effective training of neural networks requires much data. In the low-data regime, parameters are underdetermined, and learnt networks generalise poorly. Data Augmentation alleviates this by using existing data more effectively. However standard data augmentation produces only limited plausible alternative data. Given there is potential to generate a much broader set of augmentations, we design and train a generative model to do data augmentation. The model, based on image conditional Generative Adversarial Networks, takes data from a source domain and learns to take any data item and generalise it to generate other within-class data items. As this generative process does not depend on the classes themselves, it can be applied to novel unseen classes of data. We show that a Data Augmentation Generative Adversarial Network (DAGAN) augments standard vanilla classifiers well. We also show a DAGAN can enhance few-shot learning systems such as Matching Networks. We demonstrate these approaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and VGG-Face data. In our experiments we can see over 13{\%} increase in accuracy in the low-data regime experiments in Omniglot (from 69{\%} to 82{\%}), EMNIST (73.9{\%} to 76{\%}) and VGG-Face (4.5{\%} to 12{\%}); in Matching Networks for Omniglot we observe an increase of 0.5{\%} (from 96.9{\%} to 97.4{\%}) and an increase of 1.8{\%} in EMNIST (from 59.5{\%} to 61.3{\%}).},
 author = {Antoniou, Antreas and Storkey, Amos and Edwards, Harrison},
 date = {11/12/2017},
 title = {Data Augmentation Generative Adversarial Networks},
 url = {http://arxiv.org/pdf/1711.04340v3},
 keywords = {Computer Science - Computer Vision and Pattern Recognition;Computer Science - Learning;Computer Science - Neural and Evolutionary Computing;Statistics - Machine Learning},
 file = {1711.04340:Attachments/1711.04340.pdf:application/pdf}
}


@article{Anwar.2017,
 author = {Anwar, Sajid and Hwang, Kyuyeon and Sung, Wonyong},
 year = {2017},
 title = {Structured Pruning of Deep Convolutional Neural Networks},
 pages = {1--18},
 volume = {13},
 number = {3},
 issn = {1550-4832},
 journal = {ACM Journal on Emerging Technologies in Computing Systems},
 doi = {10.1145/3005348},
 file = {3005348:Attachments/3005348.pdf:application/pdf}
}


@article{ArnaudDubois.2018,
 author = {Dubois, A. and Levecq, O. and Azimani, H. and Siret, David and Barut, Ana{\"i}s and Suppa, Mariano and {Del Marmol}, V{\'e}ronique and Malvehy, Josep and Cinotti, Elisa and Rubegni, Pietro and Perrot, Jean-Luc},
 year = {2018},
 title = {Line-field confocal optical coherence tomography for high-resolution noninvasive imaging of skin tumors},
 keywords = {confocal microscopy;Glasses;Image resolution;Melanoma;Microscopes;optical coherence tomography;optical imaging;Skin;skin cancer;Tissue optics;Tissues;Tumors},
 pages = {1--9},
 journal = {Journal of Biomedical Optics 23},
 doi = {10.1117/1.JBO.23.10.106007},
 file = {Arnaud Dubois, Olivier Levecq et al 2018 - Line-field confocal optical coherence tomography:Attachments/Arnaud Dubois, Olivier Levecq et al 2018 - Line-field confocal optical coherence tomography.pdf:application/pdf}
}


@misc{Bahoshy.2022,
 author = {Bahoshy, Louis P.},
 year = {2022},
 title = {What is Optical Coherence Tomography (OCT)? 3D DIGITAL EYE EXAMS},
 url = {https://stoneycreekeyecare.com/what-is-optical-coherence-tomography-oct/},
 urldate = {25.04.2022}
}


@article{Barron.1993,
 author = {{Barron A.}, R.},
 year = {1993},
 title = {Universal approximation bounds for superpositions of a sigmoidal function},
 pages = {930--945},
 volume = {39},
 journal = {IEEE Transactions on Information Theory},
 doi = {10.1109/18.256500},
 file = {R 1993 - Universal approximation bounds for superpositions:Attachments/R 1993 - Universal approximation bounds for superpositions.pdf:application/pdf}
}


@misc{Beers.2021,
 author = {Beers, Brian},
 year = {2021},
 title = {Regression Definition: What Is Regression?},
 url = {https://www.investopedia.com/terms/r/regression.asp}
}


@article{BenCohen.2018,
 abstract = {2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018);2018; ; ;10.1109/ISBI.2018.8363762},
 author = {Ben-Cohen, Avi and Klang, Eyal and Amitai, Michal Marianne and Goldberger, Jacob and Greenspan, Hayit},
 year = {2018},
 title = {Anatomical data augmentation for CNN based pixel-wise classification},
 keywords = {augmentation;CT;liver;semi-supervised learning},
 pages = {1096--1099},
 journal = {IEEE 15th International Symposium on Biomedical Imaging (ISBI)},
 doi = {10.1109/ISBI.2018.8363762},
 file = {Anatomical{\_}data{\_}augmentation{\_}for{\_}CNN{\_}based{\_}pixel-wise{\_}classification:Attachments/Anatomical{\_}data{\_}augmentation{\_}for{\_}CNN{\_}based{\_}pixel-wise{\_}classification.pdf:application/pdf}
}


@article{Bengio.2004,
 author = {Bengio, Yoshua and Grandvalet, Yves},
 year = {2004},
 title = {No unbiased estimator of the variance of k-fold cross-validation},
 pages = {1089--1105},
 volume = {5},
 number = {Sep},
 journal = {Journal of machine learning research},
 file = {Bengio, Grandvalet 2004 - No unbiased estimator:Attachments/Bengio, Grandvalet 2004 - No unbiased estimator.pdf:application/pdf}
}


@book{Bille.2019,
 author = {Bille, Josef F.},
 year = {2019},
 title = {High resolution imaging in microscopy and ophthalmology: new frontiers in biomedical optics},
 publisher = {Springer},
 file = {Bille 2019 - High resolution imaging in microscopy:Attachments/Bille 2019 - High resolution imaging in microscopy.pdf:application/pdf}
}


@article{BioucasDiasJoseM..2010,
 author = {Bioucas-Dias, Jose M. and {Figueiredo M{\'a}rio A. T.}},
 year = {2010},
 title = {Multiplicative Noise Removal Using Variable Splitting and Constrained Optimization},
 pages = {1720--1730},
 journal = {IEEE Transactions on Image Processing 19},
 doi = {10.1109/TIP.2010.2045029}
}


@proceedings{Bouman.2012,
 year = {2012},
 title = {Computational Imaging X},
 publisher = {SPIE},
 series = {SPIE Proceedings},
 editor = {Bouman, Charles A. and Pollak, Ilya and Wolfe, Patrick J.}
}


@article{Boyko.1994,
 abstract = {Previous publications have advocated that clinicians choose the most sensitive diagnostic test to rule out disease and the most specific diagnostic test to rule in disease. This paper critically examines the validity of these recommendations. First, the author finds that following these recommendations does not lead to the highest disease probability for a positive test result (thereby best ruling in disease) or the lowest disease probability for a negative test result (thereby best ruling out disease). In general, the ability of a diagnostic test to lead to the highest (rule in) or lowest (rule out) disease probability should be judged based on likelihood ratios. Next, by comparing expected utilities, the author considers whether the most specific test leads to the best clinical outcome when a rule-in strategy is clinically advisable, i.e., when the costs of false-positive results are high, and whether the most sensitive test leads to the best clinical outcome when a rule-out strategy is clinically advisable, i.e., when the costs of false-negative results are high. The author again demonstrates that the greatest clinical utility is not always achieved by using the most specific test in a rule-in decision or the most sensitive test in a rule-out decision. Tradeoffs between sensitivity, specificity, disease probability, and utilities of correct and incorrect disease classifications by the diagnostic test must be simultaneously captured to determine which strategy maxi mizes clinical utility. Key words: diagnostic tests; utilities. (Med Decis Making 1994;14:175- 179)},
 author = {Boyko, Edward J.},
 year = {1994},
 title = {Ruling Out or Ruling In Disease with the Most sensitiue or Specific Diagnostic Test: Short Cut or Wrong Turn ?},
 pages = {175--179},
 journal = {Medical Decision Making 14},
 doi = {10.1177/0272989X9401400210},
 file = {Boyko 1994 - Ruling Out or Ruling:Attachments/Boyko 1994 - Ruling Out or Ruling.pdf:application/pdf}
}


@article{BrianR.White.2003,
 abstract = {An ultra-high-speed spectral domain optical Doppler tomography (SD-ODT) system is used to acquire images of blood flow in a human retina in vivo, at 29,000 depth profiles (A-lines) per second and with data acquisition over 99{\%} of the measurement time. The phase stability of the system is examined and image processing algorithms are presented that allow accurate determination of bi-directional Doppler shifts. Movies are presented of human retinal flow acquired at 29 frames per second with 1000 A-lines per frame over a time period of 3.28 seconds, showing accurate determination of vessel boundaries and time-dependent bi-directional flow dynamics in artery-vein pairs. The ultra-high-speed SD-ODT system allows visualization of the pulsatile nature of retinal blood flow, detects blood flow within the choroid and retinal capillaries, and provides information on the cardiac cycle. In summary, accurate video rate imaging of retinal blood flow dynamics is demonstrated at ocular exposure levels below 600 $\backslash$textmuW.},
 author = {{Brian R. White} and {Mark C. Pierce} and {Nader Nassif} and {Barry Cense} and {B. Hyle Park} and {Guillermo J. Tearney} and {Brett E. Bouma} and {Teresa C. Chen} and {Johannes F. de Boer}},
 year = {2003},
 title = {In vivo dynamic human retinal blood flow imaging using ultra-high-speed spectral domain optical Doppler tomography},
 keywords = {Flow diagnostics;Image processing algorithms;Image quality;Laser Doppler velocimetry;Ophthalmology;optical coherence tomography;Optical Doppler tomography;Retinal nerve fiber layer;Spectral domain optical coherence tomography;Tomographic image processing},
 pages = {3490--3497},
 volume = {11},
 number = {25},
 journal = {Opt. Express},
 doi = {10.1364/OE.11.003490},
 file = {Brian R White, Mark C Pierce et al 2003 - In vivo dynamic human retinal:Attachments/Brian R White, Mark C Pierce et al 2003 - In vivo dynamic human retinal.pdf:application/pdf}
}


@misc{Brownlee.2017,
 author = {Brownlee, Jason},
 year = {2017},
 title = {Gentle Introduction to the Adam Optimization Algorithm for Deep Learning},
 url = {https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/},
 urldate = {15.04.2022},
 series = {Deep Learning Performance}
}


@book{Brownlee.2019,
 author = {Brownlee, Jason},
 year = {2019},
 title = {Better Deep Learning: Train Faster, Reduce Overfitting, and Make Better Predictions},
 url = {https://machinelearningmastery.com/better-deep-learning/},
 publisher = {{Brownlee, Jason}}
}


@article{Campos.2019,
 abstract = {EURASIP Journal on Image and Video Processing, 2019, doi:10.1186/s13640-019-0445-4},
 author = {Campos, Gabriel Fillipe Centini and Mastelini, Saulo Martiello and Aguiar, Gabriel Jonas and Mantovani, Rafael Gomes and de Melo, Leonimer Fl{\'a}vio and Barbon, Sylvio},
 year = {2019},
 title = {Machine learning hyperparameter selection for Contrast Limited Adaptive Histogram Equalization},
 journal = {EURASIP Journal on Image and Video Processing},
 doi = {10.1186/s13640-019-0445-4},
 file = {s13640-019-0445-4:Attachments/s13640-019-0445-4.pdf:application/pdf}
}


@article{Celi.2014,
 abstract = {Optical coherence tomography (OCT) is a catheter-based medical imaging technique that produces cross-sectional images of blood vessels. This technique is particularly useful for studying coronary atherosclerosis. In this paper, we present a new framework that allows a segmentation and quantification of OCT images of coronary arteries to define the plaque type and stenosis grading. These analyses are usually carried out on-line on the OCT-workstation where measuring is mainly operator-dependent and mouse-based. The aim of this program is to simplify and improve the processing of OCT images for morphometric investigations and to present a fast procedure to obtain 3D geometrical models that can also be used for external purposes such as for finite element simulations. The main phases of our toolbox are the lumen segmentation and the identification of the main tissues in the artery wall. We validated the proposed method with identification and segmentation manually performed by expert OCT readers. The method was evaluated on ten datasets from clinical routine and the validation was performed on 210 images randomly extracted from the pullbacks. Our results show that automated segmentation of the vessel and of the tissue components are possible off-line with a precision that is comparable to manual segmentation for the tissue component and to the proprietary-OCT-console for the lumen segmentation. Several OCT sections have been processed to provide clinical outcome.},
 author = {Celi, Simona and Berti, Sergio},
 year = {2014},
 title = {In-vivo segmentation and quantification of coronary lesions by optical coherence tomography images for a lesion type definition and stenosis grading},
 url = {https://www.sciencedirect.com/science/article/pii/S1361841514001054},
 keywords = {3D Reconstruction;Coronary arteries;optical coherence tomography;Plaque morphology;Vessel segmentation},
 pages = {1157--1168},
 journal = {Medical image analysis 18},
 doi = {10.1016/j.media.2014.06.011}
}


@article{Chen.2012,
 author = {Chen, Bo and Cai, Jin-Lin and Chen, Wen-Sheng and Li, Yan},
 year = {2012},
 title = {A Multiplicative Noise Removal Approach Based on Partial Differential Equation Model},
 pages = {1--14},
 issn = {1024-123X},
 journal = {Mathematical Problems in Engineering},
 doi = {10.1155/2012/242043},
 file = {242043:Attachments/242043.pdf:application/pdf}
}


@article{Chicco.2020,
 abstract = {BACKGROUND

To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets.

RESULTS

The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset.

CONCLUSIONS

In this article, we show how MCC produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of MCC in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
 author = {Chicco, Davide and Jurman, Giuseppe},
 year = {2020},
 title = {The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation},
 keywords = {Accuracy;Algorithms;Binary classification;Biostatistics;Computational Biology/statistics {\&} numerical data;Confusion matrices;Correlation of Data;Data Interpretation, Statistical;Dataset imbalance;F1 score;Genomics;Machine Learning;Machine Learning/statistics {\&} numerical data;Matthews correlation coefficient},
 pages = {6},
 journal = {BMC genomics 21},
 doi = {10.1186/s12864-019-6413-7},
 file = {12864{\_}2019{\_}Article{\_}6413:Attachments/12864{\_}2019{\_}Article{\_}6413.pdf:application/pdf}
}


@article{Chicco.2020b,
 abstract = {BACKGROUND

To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets.

RESULTS

The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset.

CONCLUSIONS

In this article, we show how MCC produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of MCC in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
 author = {Chicco, Davide and Jurman, Giuseppe},
 year = {2020},
 title = {The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation},
 keywords = {Accuracy;Algorithms;Binary classification;Biostatistics;Computational Biology/statistics {\&} numerical data;Confusion matrices;Correlation of Data;Data Interpretation, Statistical;Dataset imbalance;F1 score;Genomics;Machine Learning;Machine Learning/statistics {\&} numerical data;Matthews correlation coefficient},
 pages = {6},
 journal = {BMC genomics 21},
 doi = {10.1186/s12864-019-6413-7},
 file = {s12864-019-6413-7:Attachments/s12864-019-6413-7.pdf:application/pdf}
}


@article{Chicco.2021,
 abstract = {IEEE Access;2021;9; ;10.1109/ACCESS.2021.3068614},
 author = {Chicco, Davide and Starovoitov, Valery and Jurman, Giuseppe},
 year = {2021},
 title = {The Benefits of the Matthews Correlation Coefficient (MCC) Over the Diagnostic Odds Ratio (DOR) in Binary Classification Assessment},
 pages = {47112--47124},
 journal = {IEEE Access 9},
 doi = {10.1109/ACCESS.2021.3068614},
 file = {ThebenefitsoftheMatthewscorrelationMCCoverthediagnosticoddsratioDORinbinaryclassification-21:Attachments/ThebenefitsoftheMatthewscorrelationMCCoverthediagnosticoddsratioDORinbinaryclassification-21.pdf:application/pdf}
}


@article{Chicco.2021b,
 abstract = {Evaluating binary classifications is a pivotal task in statistics and machine learning, because it can influence decisions in multiple areas, including for example prognosis or therapies of patients in critical conditions. The scientific community has not agreed on a general-purpose statistical indicator for evaluating two-class confusion matrices (having true positives, true negatives, false positives, and false negatives) yet, even if advantages of the Matthews correlation coefficient (MCC) over accuracy and F1 score have already been shown.In this manuscript, we reaffirm that MCC is a robust metric that summarizes the classifier performance in a single value, if positive and negative cases are of equal importance. We compare MCC to other metrics which value positive and negative cases equally: balanced accuracy (BA), bookmaker informedness (BM), and markedness (MK). We explain the mathematical relationships between MCC and these indicators, then show some use cases and a bioinformatics scenario where these metrics disagree and where MCC generates a more informative response.Additionally, we describe three exceptions where BM can be more appropriate: analyzing classifications where dataset prevalence is unrepresentative, comparing classifiers on different datasets, and assessing the random guessing level of a classifier. Except in these cases, we believe that MCC is the most informative among the single metrics discussed, and suggest it as standard measure for scientists of all fields. A Matthews correlation coefficient close to +1, in fact, means having high values for all the other confusion matrix metrics. The same cannot be said for balanced accuracy, markedness, bookmaker informedness, accuracy and F1 score.},
 author = {Chicco, Davide and T{\"o}tsch, Niklas and Jurman, Giuseppe},
 year = {2021},
 title = {The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation},
 keywords = {Balanced accuracy;Binary classification;Bookmaker informedness;Confusion matrix;Machine Learning;Markedness;Matthews correlation coefficient},
 pages = {13},
 journal = {BioData mining 14},
 doi = {10.1186/s13040-021-00244-z},
 file = {The{\_}Matthews{\_}correlation{\_}coefficient{\_}MCC{\_}is{\_}more{\_}r:Attachments/The{\_}Matthews{\_}correlation{\_}coefficient{\_}MCC{\_}is{\_}more{\_}r.pdf:application/pdf}
}


@article{Chicco.2021c,
 abstract = {Evaluating binary classifications is a pivotal task in statistics and machine learning, because it can influence decisions in multiple areas, including for example prognosis or therapies of patients in critical conditions. The scientific community has not agreed on a general-purpose statistical indicator for evaluating two-class confusion matrices (having true positives, true negatives, false positives, and false negatives) yet, even if advantages of the Matthews correlation coefficient (MCC) over accuracy and F1 score have already been shown.In this manuscript, we reaffirm that MCC is a robust metric that summarizes the classifier performance in a single value, if positive and negative cases are of equal importance. We compare MCC to other metrics which value positive and negative cases equally: balanced accuracy (BA), bookmaker informedness (BM), and markedness (MK). We explain the mathematical relationships between MCC and these indicators, then show some use cases and a bioinformatics scenario where these metrics disagree and where MCC generates a more informative response.Additionally, we describe three exceptions where BM can be more appropriate: analyzing classifications where dataset prevalence is unrepresentative, comparing classifiers on different datasets, and assessing the random guessing level of a classifier. Except in these cases, we believe that MCC is the most informative among the single metrics discussed, and suggest it as standard measure for scientists of all fields. A Matthews correlation coefficient close to +1, in fact, means having high values for all the other confusion matrix metrics. The same cannot be said for balanced accuracy, markedness, bookmaker informedness, accuracy and F1 score.},
 author = {Chicco, Davide and T{\"o}tsch, Niklas and Jurman, Giuseppe},
 year = {2021},
 title = {The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation},
 keywords = {Balanced accuracy;Binary classification;Bookmaker informedness;Confusion matrix;Machine Learning;Markedness;Matthews correlation coefficient},
 pages = {13},
 journal = {BioData mining 14},
 doi = {10.1186/s13040-021-00244-z},
 file = {13040{\_}2021{\_}Article{\_}244:Attachments/13040{\_}2021{\_}Article{\_}244.pdf:application/pdf}
}


@article{Cho.2015,
 author = {Cho, Junghwan and Lee, Kyewook and Shin, Ellie and Choy, Garry and Do, Synho},
 year = {2015},
 title = {How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?},
 keywords = {computer vision;Evolutionary Computing (cs.NE);FOS: Computer;information sciences;Machine Learning (cs.LG);Neural;Pattern Recognition (cs.CV)},
 journal = {ICLR},
 doi = {10.48550/ARXIV.1511.06348},
 file = {Cho, Lee et al 2015 - How much data is needed:Attachments/Cho, Lee et al 2015 - How much data is needed.pdf:application/pdf}
}


@proceedings{Citeseer.2013,
 year = {2013},
 title = {Proc. icml},
 institution = {Citeseer}
}


@misc{CommunityEditors.2022,
 author = {{Community Editors}},
 year = {2022},
 title = {OpenCV 2.4.13.7 documentation},
 url = {https://docs.opencv.org/2.4/},
 urldate = {05.05.2022}
}


@article{CruzRoa.2013,
 abstract = {This paper presents and evaluates a deep learning architecture for automated basal cell carcinoma cancer detection that integrates (1) image representation learning, (2) image classification and (3) result interpretability. A novel characteristic of this approach is that it extends the deep learning architecture to also include an interpretable layer that highlights the visual patterns that contribute to discriminate between cancerous and normal tissues patterns, working akin to a digital staining which spotlights image regions important for diagnostic decisions. Experimental evaluation was performed on set of 1,417 images from 308 regions of interest of skin histopathology slides, where the presence of absence of basal cell carcinoma needs to be determined. Different image representation strategies, including bag of features (BOF), canonical (discrete cosine transform (DCT) and Haar-based wavelet transform (Haar)) and proposed learned-from-data representations, were evaluated for comparison. Experimental results show that the representation learned from a large histology image data set has the best overall performance (89.4{\%} in F-measure and 91.4{\%} in balanced accuracy), which represents an improvement of around 7{\%} over canonical representations and 3{\%} over the best equivalent BOF representation.},
 author = {Cruz-Roa, Angel Alfonso and {Arevalo Ovalle}, John Edison and Madabhushi, Anant and {Gonz{\'a}lez Osorio}, Fabio Augusto},
 year = {2013},
 title = {A Deep Learning Architecture for Image Representation, Visual Interpretability and Automated Basal-Cell Carcinoma Cancer Detection},
 journal = {Medical Image MICCAI, Computing and Computer-Assisted Intervention},
 file = {Cruz-Roa, Arevalo Ovalle et al 2013 - A Deep Learning Architecture:Attachments/Cruz-Roa, Arevalo Ovalle et al 2013 - A Deep Learning Architecture.pdf:application/pdf}
}


@article{DavidMWPowers.2007,
 author = {{David M W Powers}},
 year = {2007},
 title = {Evaluation: From Precision, Recall and F-Factor to ROC, Informedness, Markedness {\&} Correlation},
 file = {David M W Powers 2007 - Evaluation:Attachments/David M W Powers 2007 - Evaluation.pdf:application/pdf}
}


@article{Delgado.2019,
 abstract = {We show that Cohen's Kappa and Matthews Correlation Coefficient (MCC), both extended and contrasted measures of performance in multi-class classification, are correlated in most situations, albeit can differ in others. Indeed, although in the symmetric case both match, we consider different unbalanced situations in which Kappa exhibits an undesired behaviour, i.e. a worse classifier gets higher Kappa score, differing qualitatively from that of MCC. The debate about the incoherence in the behaviour of Kappa revolves around the convenience, or not, of using a relative metric, which makes the interpretation of its values difficult. We extend these concerns by showing that its pitfalls can go even further. Through experimentation, we present a novel approach to this topic. We carry on a comprehensive study that identifies an scenario in which the contradictory behaviour among MCC and Kappa emerges. Specifically, we find out that when there is a decrease to zero of the entropy of the elements out of the diagonal of the confusion matrix associated to a classifier, the discrepancy between Kappa and MCC rise, pointing to an anomalous performance of the former. We believe that this finding disables Kappa to be used in general as a performance measure to compare classifiers.},
 author = {Delgado, Rosario and Tibau, Xavier-Andoni},
 year = {2019},
 title = {Why Cohen's Kappa should be avoided as performance measure in classification},
 keywords = {Classification/methods;Data Analysis;Datasets as Topic;Models, Theoretical;Reproducibility of Results;Supervised Machine Learning},
 journal = {PloS one 14},
 doi = {10.1371/journal.pone.0222916},
 file = {file:Attachments/file.pdf:application/pdf}
}


@article{Devalla.2018,
 abstract = {Given that the neural and connective tissues of the optic nerve head (ONH) exhibit complex morphological changes with the development and progression of glaucoma, their simultaneous isolation from optical coherence tomography (OCT) images may be of great interest for the clinical diagnosis and management of this pathology. A deep learning algorithm (custom U-NET) was designed and trained to segment 6 ONH tissue layers by capturing both the local (tissue texture) and contextual information (spatial arrangement of tissues). The overall Dice coefficient (mean of all tissues) was 0.91 $\pm$ 0.05 when assessed against manual segmentations performed by an expert observer. Further, we automatically extracted six clinically relevant neural and connective tissue structural parameters from the segmented tissues. We offer here a robust segmentation framework that could also be extended to the 3D segmentation of the ONH tissues.},
 author = {Devalla, Sripad Krishna and Renukanand, Prajwal K. and Sreedhar, Bharathwaj K. and Subramanian, Giridhar and Zhang, Liang and Perera, Shamira and Mari, Jean-Martial and Chin, Khai Sing and Tun, Tin A. and Strouthidis, Nicholas G. and Aung, Tin and Thi{\'e}ry, Alexandre H. and Girard, Micha{\"e}l J. A.},
 year = {2018},
 title = {DRUNET: a dilated-residual U-Net deep learning network to segment optic nerve head tissues in optical coherence tomography images},
 pages = {3244--3326},
 journal = {Biomedical optics express 9},
 file = {boe-9-7-3244:Attachments/boe-9-7-3244.pdf:application/pdf}
}


@article{Devalla.2018b,
 abstract = {Purpose

To develop a deep learning approach to digitally stain optical coherence tomography (OCT) images of the optic nerve head (ONH).

Methods

A horizontal B-scan was acquired through the center of the ONH using OCT (Spectralis) for one eye of each of 100 subjects (40 healthy and 60 glaucoma). All images were enhanced using adaptive compensation. A custom deep learning network was then designed and trained with the compensated images to digitally stain (i.e., highlight) six tissue layers of the ONH. The accuracy of our algorithm was assessed (against manual segmentations) using the dice coefficient, sensitivity, specificity, intersection over union (IU), and accuracy. We studied the effect of compensation, number of training images, and performance comparison between glaucoma and healthy subjects.

Results

For images it had not yet assessed, our algorithm was able to digitally stain the retinal nerve fiber layer + prelamina, the RPE, all other retinal layers, the choroid, and the peripapillary sclera and lamina cribrosa. For all tissues, the dice coefficient, sensitivity, specificity, IU, and accuracy (mean) were 0.84 $\pm$ 0.03, 0.92 $\pm$ 0.03, 0.99 $\pm$ 0.00, 0.89 $\pm$ 0.03, and 0.94 $\pm$ 0.02, respectively. Our algorithm performed significantly better when compensated images were used for training (P {\textless} 0.001). Besides offering a good reliability, digital staining also performed well on OCT images of both glaucoma and healthy individuals.

Conclusions

Our deep learning algorithm can simultaneously stain the neural and connective tissues of the ONH, offering a framework to automatically measure multiple key structural parameters of the ONH that may be critical to improve glaucoma management.},
 author = {Devalla, Sripad Krishna and Chin, Khai Sing and Mari, Jean-Martial and Tun, Tin A. and Strouthidis, Nicholas G. and Aung, Tin and Thi{\'e}ry, Alexandre H. and Girard, Micha{\"e}l J. A.},
 year = {2018},
 title = {A Deep Learning Approach to Digitally Stain Optical Coherence Tomography Images of the Optic Nerve Head},
 keywords = {Adult;Algorithms;Female;Glaucoma/diagnosis;Humans;Machine Learning;Male;Middle Aged;Nerve Fibers/pathology;Optic Disk/pathology;Reproducibility of Results;Retinal Ganglion Cells/pathology;Tomography, Optical Coherence/methods;Visual Fields},
 pages = {63--74},
 volume = {59},
 number = {1},
 journal = {Investigative ophthalmology {\&} visual science},
 doi = {10.1167/iovs.17-22617},
 file = {i1552-5783-59-1-63:Attachments/i1552-5783-59-1-63.pdf:application/pdf}
}


@article{Douglass.2020,
 abstract = {Physical and Engineering Sciences in Medicine, https://doi.org/10.1007/s13246-020-00913-z},
 author = {Douglass, Michael J. J. and G{\'e}ron, Aur{\'e}lien},
 year = {2020},
 title = {Book Review: Hands-on Machine Learning with Scikit-Learn, Keras, and Tensorflow: 2nd edition},
 pages = {1135--1136},
 volume = {43},
 issn = {2662-4729},
 journal = {Physical and Engineering Sciences in Medicine},
 doi = {10.1007/s13246-020-00913-z},
 file = {Douglass2020{\_}Article{\_}BookReviewHands-onMachineLearn:Attachments/Douglass2020{\_}Article{\_}BookReviewHands-onMachineLearn.pdf:application/pdf}
}


@book{Drexler.2008,
 author = {Drexler, Wolfgang and Fujimoto, James G.},
 year = {2008},
 title = {Optical coherence tomography: Technology and applications},
 keywords = {optical coherence tomography;Tomography, Optical Coherence},
 address = {Berlin},
 publisher = {Springer},
 isbn = {9783540775492},
 series = {Biological and medical physics, biomedical engineering},
 file = {2008{\_}Book{\_}OpticalCoherenceTomography:Attachments/2008{\_}Book{\_}OpticalCoherenceTomography.pdf:application/pdf}
}


@article{Dreyfus.1990,
 author = {Dreyfus, Stuart E.},
 year = {1990},
 title = {Artificial neural networks, back propagation, and the Kelley-Bryson gradient procedure},
 pages = {926--928},
 journal = {Journal of guidance, control, and dynamics 13},
 file = {Dreyfus 1990 - Artificial neural networks:Attachments/Dreyfus 1990 - Artificial neural networks.pdf:application/pdf}
}


@article{E.Beaurepaire.1998,
 abstract = {We present a new microscopy system for imaging in turbid media that is based on the spatial coherence gate principle and generates in parallel a complete two-dimensional head-on image without scanning. This system has been implemented in a commercial microscope and preserves the lateral resolution of the optics used. With a spatially incoherent source, speckle-free images with diffraction-limited resolution are recorded at successive depths with shot-noise-limited detection. The setup comprises a photoelastic modulator for path difference modulation and a two-dimensional CCD array and uses a multiplexed lock-in detection scheme.},
 author = {Beaurepaire, E. and Boccara, A. C. and Lebec, M. and Blanchot, L. and Saint-Jalmes, H.},
 year = {1998},
 title = {Full-field optical coherence microscopy},
 keywords = {Beam splitters;biological imaging;CCD;charge-coupled device;Coherence imaging;In vivo imaging;Medical;Microscopy;optical coherence tomography;Phase shift;Refractive index;Scattering media},
 pages = {244--246},
 journal = {Opt. Lett. 23},
 doi = {10.1364/OL.23.000244}
}


@book{Edgar.2017,
 author = {Edgar, Thomas and Manz, David},
 year = {2017},
 title = {Research methods for cyber security},
 publisher = {Syngress}
}


@article{Erb.1993,
 abstract = {Neurocomputing is computer modeling based, in part, upon simulation of the structure and function of the brain. Neural networks excel in pattern recognition, that is, the ability to recognize a set of previously learned data. Although their use is rapidly growing in engineering, they are new to the pharmaceutical community. This article introduces neurocomputing using the backpropagation network (BPN).},
 author = {Erb, Randall J.},
 year = {1993},
 title = {Introduction to Backpropagation Neural Network Computation},
 pages = {165--170},
 volume = {10},
 issn = {1573-904X},
 journal = {Pharmaceutical Research},
 doi = {10.1023/A:1018966222807},
 file = {Erb 1993 - Introduction to Backpropagation Neural Network:Attachments/Erb 1993 - Introduction to Backpropagation Neural Network.pdf:application/pdf}
}


@article{Fakoor.2013,
 author = {Fakoor, Rasool and Ladhak, Faisal and Nazi, Azade and Huber, Manfred},
 year = {2013},
 title = {Using deep learning to enhance cancer diagnosis and classification},
 journal = {Proceedings of the 30th International Conference on Machine Learning,},
 file = {Fakoor, Ladhak et al 2013 - Using deep learning to enhance:Attachments/Fakoor, Ladhak et al 2013 - Using deep learning to enhance.pdf:application/pdf}
}


@article{Fawcett.2006,
 author = {Fawcett, Tom},
 year = {2006},
 title = {An introduction to ROC analysis},
 pages = {861--874},
 volume = {27},
 number = {8},
 issn = {01678655},
 journal = {Pattern Recognition Letters},
 doi = {10.1016/j.patrec.2005.10.010},
 file = {roc:Attachments/roc.pdf:application/pdf}
}


@article{Fingler.2008,
 abstract = {purpose. To test the hypothesis that a novel phase-contrast optical coherence tomography (OCT) system can image retinal and choroidal vessels in the living mouse.  methods. A high-speed spectral domain optical coherence tomography (SDOCT) system, which measures the reflections for the entire depth of the retina at once with each axial scan (A-scan), was developed for mouse retinal imaging. Acquiring multiple A-scans over a transverse line across the mouse retina offers a two-dimensional cross-sectional image (B-scan); several neighboring B-scans can be assembled into a three-dimensional OCT image. To visualize mobility and transverse flow in retinal vessels, the statistical variance of phase for each location was calculated from multiple B-scans acquired successively for the same retinal cross-section. Such measures of phase variance offer a direct measure of motions over a large dynamic range of flow velocities.  results. Three-dimensional phase-contrast images of the live mouse retina were created using multiple two-dimensional cross-sectional image slices through the retina. For the data presented here, each cross-sectional phase-contrast slice resulted from five images of 100 or 200 transverse pixels, acquired over 25 ms or 50 ms, respectively. The approach offered clear identification of motion regions at different depths, including flow in the retinal microvasculature and in the choroidal vessels.  conclusions. Phase-contrast OCT enables three-dimensional visualization of retinal and choroidal vasculature in vivo.},
 author = {Fingler, Jeff and Readhead, Carol and Schwartz, Daniel M. and Fraser, Scott E.},
 year = {2008},
 title = {Phase-Contrast OCT Imaging of Transverse Flows in the Mouse Retina and Choroid},
 pages = {5055--5059},
 volume = {49},
 number = {11},
 journal = {Investigative ophthalmology {\&} visual science},
 doi = {10.1167/iovs.07-1627},
 file = {Fingler, Readhead et al 2008 - Phase-Contrast OCT Imaging of Transverse:Attachments/Fingler, Readhead et al 2008 - Phase-Contrast OCT Imaging of Transverse.pdf:application/pdf}
}


@article{Fletcher.2005,
 author = {Fletcher, W.},
 year = {2005},
 title = {Robert and W Fletcher, Suzanne},
 pages = {207},
 journal = {lippincott Williams and Wilkins}
}


@article{Fushiki.2011,
 author = {Fushiki, Tadayoshi},
 year = {2011},
 title = {Estimation of prediction error by using K-fold cross-validation},
 pages = {137--146},
 journal = {Stat Comput (Statistics and Computing) 21},
 doi = {10.1007/s11222-009-9153-8},
 file = {Fushiki2011{\_}Article{\_}EstimationOfPredictionErrorByU:Attachments/Fushiki2011{\_}Article{\_}EstimationOfPredictionErrorByU.pdf:application/pdf}
}


@article{Gessert.2018,
 abstract = {Advanced atherosclerosis in the coronary arteries is one of the leading causes of deaths worldwide while being preventable and treatable. In order to image atherosclerotic lesions (plaque), intravascular optical coherence tomography (IVOCT) can be used. The technique provides high-resolution images of arterial walls which allows for early plaque detection by experts. Due to the vast amount of IVOCT images acquired in clinical routines, automatic plaque detection has been addressed. For example, attenuation profiles in single A-Scans of IVOCT images are examined to detect plaque. We address automatic plaque classification from entire IVOCT images, the cross-sectional view of the artery, using deep feature learning. In this way, we take context between A-Scans into account and we directly learn relevant features from the image source without the need for handcrafting features.},
 author = {Gessert, Nils and Heyder, Markus and Latus, Sarah and Lutz, Matthias and Schlaefer, Alexander},
 year = {2018},
 title = {Plaque Classification in Coronary Arteries from IVOCT Images Using  Convolutional Neural Networks and Transfer Learning},
 url = {http://arxiv.org/pdf/1804.03904v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 pages = {1--273},
 volume = {13},
 issn = {1861-6410},
 journal = {International Journal of Computer Assisted Radiology and Surgery},
 doi = {10.1007/s11548-018-1766-y},
 file = {1804.03904:Attachments/1804.03904.pdf:application/pdf}
}


@article{Gessert.2019,
 abstract = {Coronary heart disease is a common cause of death despite being preventable. To treat the underlying plaque deposits in the arterial walls, intravascular optical coherence tomography can be used by experts to detect and characterize the lesions. In clinical routine, hundreds of images are acquired for each patient, which require automatic plaque detection for fast and accurate decision support. So far, automatic approaches rely on classic machine learning methods and deep learning solutions have rarely been studied. Given the success of deep learning methods with other imaging modalities, a thorough understanding of deep learning-based plaque detection for future clinical decision support systems is required. We address this issue with a new data set consisting of in vivo patient images labeled by three trained experts. Using this data set, we employ the state-of-the-art deep learning models that directly learn plaque classification from the images. For improved performance, we study different transfer learning approaches. Furthermore, we investigate the use of Cartesian and polar image representations and employ data augmentation techniques tailored to each representation. We fuse both representations in a multi-path architecture for more effective feature exploitation. Last, we address the challenge of plaque differentiation in addition to detection. Overall, we find that our combined model performs best with an accuracy of 91.7{\%}, a sensitivity of 90.9{\%}, and a specificity of 92.4{\%}. Our results indicate that building a deep learning-based clinical decision support system for plaque detection is feasible.},
 author = {Gessert, Nils and Lutz, Matthias and Heyder, Markus and Latus, Sarah and Leistner, David M. and Abdelwahed, Youssef S. and Schlaefer, Alexander},
 year = {2019},
 title = {Automatic Plaque Detection in IVOCT Pullbacks Using Convolutional Neural Networks},
 keywords = {deep learning;Endovascular Procedures/methods;Humans;Image Interpretation, Computer-Assisted/methods;IVOCT;Neural Networks, Computer;plaque detection;Plaque, Atherosclerotic/diagnostic imaging;Tomography, Optical Coherence/methods;transfer learning},
 pages = {426--434},
 volume = {38},
 journal = {IEEE Transactions on Medical Imaging},
 doi = {10.1109/TMI.2018.2865659},
 file = {Automatic{\_}Plaque{\_}Detection{\_}in{\_}IVOCT{\_}Pullbacks{\_}Using{\_}Convolutional{\_}Neural{\_}Networks:Attachments/Automatic{\_}Plaque{\_}Detection{\_}in{\_}IVOCT{\_}Pullbacks{\_}Using{\_}Convolutional{\_}Neural{\_}Networks.pdf:application/pdf}
}


@article{Ghosh.2021,
 author = {Ghosh, Atin and Thiery, Alexandre H.},
 year = {2021},
 title = {On Data-Augmentation and Consistency-Based Semi-Supervised Learning},
 keywords = {Applications (stat.AP);FOS: Computer;information sciences;Machine Learning (cs.LG);Machine Learning (stat.ML)},
 doi = {10.48550/ARXIV.2101.06967},
 file = {Ghosh, Thiery 2021 - On Data-Augmentation and Consistency-Based Semi-Supervised:Attachments/Ghosh, Thiery 2021 - On Data-Augmentation and Consistency-Based Semi-Supervised.pdf:application/pdf}
}


@article{Girard.2013,
 abstract = {Measurement of optic nerve head (ONH) deformations could be useful in the clinical management of glaucoma. Here, we propose a novel three-dimensional tissue-tracking algorithm designed to be used in vivo. We carry out preliminary verification of the algorithm by testing its accuracy and its robustness. An algorithm based on digital volume correlation was developed to extract ONH tissue displacements from two optical coherence tomography (OCT) volumes of the ONH (undeformed and deformed). The algorithm was tested by applying artificial deformations to a baseline OCT scan while manipulating speckle noise, illumination and contrast enhancement. Tissue deformations determined by our algorithm were compared with the known (imposed) values. Errors in displacement magnitude, orientation and strain decreased with signal averaging and were 0.15 m, 0.15 and 0.0019, respectively (for optimized algorithm parameters). Previous computational work suggests that these errors are acceptable to provide in vivo characterization of ONH biomechanics. Our algorithm is robust to OCT speckle noise as well as to changes in illumination conditions, and increasing signal averaging can produce better results. This algorithm has potential be used to quantify ONH three-dimensional strains in vivo, of benefit in the diagnosis and identification of risk factors in glaucoma.},
 author = {Girard, Micha{\"e}l J. A. and Strouthidis, Nicholas G. and Desjardins, Adrien and Mari, Jean Martial and Ethier, C. Ross},
 year = {2013},
 title = {In vivo optic nerve head biomechanics: performance testing of a three-dimensional tracking algorithm},
 keywords = {Algorithms;Biomechanical Phenomena;Humans;Imaging, Three-Dimensional;Optic Disk/pathology/physiology;Tomography, Optical Coherence},
 journal = {Journal of the Royal Society, Interface 10},
 doi = {10.1098/rsif.2013.0459},
 file = {rsif.2013.0459:Attachments/rsif.2013.0459.pdf:application/pdf}
}


@article{Glorot.2011,
 abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training.},
 author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
 year = {2011},
 title = {Deep Sparse Rectifier Neural Networks},
 url = {https://proceedings.mlr.press/v15/glorot11a.html},
 pages = {315--323},
 volume = {15},
 journal = {Proceedings of the Fourteenth Internal Conference on Artificial Intelligence and Statistics},
 file = {Glorot, Bordes et al 2011 - Deep Sparse Rectifier Neural Networks:Attachments/Glorot, Bordes et al 2011 - Deep Sparse Rectifier Neural Networks.pdf:application/pdf}
}


@article{Gonzalo.2010,
 author = {Gonzalo, Nieves and Tearney, Guillermo J. and Serruys, Patrick W. and {van Soest}, Gijs and Okamura, Takayuki and Garcia, H{\'e}ctor M. and {van Geuns}, Robert Jan and {van der Ent}, Martin and Ligthart, Jurgen and Boum, Brett E. and others},
 year = {2010},
 title = {Second-Generation Optical Coherence Tomography in Clinical Practice: High-Speed Data Acquisition Is Highly Reproducible in Patients Undergoing Percutaneous Coronary Intervention},
 pages = {893--903},
 volume = {63},
 journal = {Revista Espa{\~n}ola de Cardiologia}
}


@article{Goodfellow.2014,
 author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 year = {2014},
 title = {Generative adversarial nets},
 volume = {27},
 journal = {Advances in neural information processing systems},
 file = {Goodfellow, Pouget-Abadie et al 2014 - Generative adversarial nets:Attachments/Goodfellow, Pouget-Abadie et al 2014 - Generative adversarial nets.pdf:application/pdf}
}


@book{Goodfellow.2016,
 author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
 year = {2016},
 title = {Deep Learning},
 url = {http://www.deeplearningbook.org},
 address = {ACADEMIA, Accelerating the world's research.},
 publisher = {{MIT Press}},
 file = {Goodfellow, Bengio et al 2016 - Deep Learning:Attachments/Goodfellow, Bengio et al 2016 - Deep Learning.pdf:application/pdf}
}


@misc{GoogleDevelopers.2022,
 author = {{Google Developers}},
 year = {2022},
 title = {Generalization: Definition, Machine Learning Crash Course},
 url = {https://developers.google.com/machine-learning/crash-course/generalization/video-lecture},
 urldate = {15.04.2022}
}


@proceedings{Gordon.2011,
 year = {2011},
 title = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
 address = {Fort Lauderdale, FL, USA},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 editor = {Gordon, Geoffrey and Dunson, David and Dud{\'i}k, Miroslav}
}


@article{Grandini.8132020,
 abstract = {Classification tasks in machine learning involving more than two classes are known by the name of {\textquotedbl}multi-class classification{\textquotedbl}. Performance indicators are very useful when the aim is to evaluate and compare different classification models or machine learning techniques. Many metrics come in handy to test the ability of a multi-class classifier. Those metrics turn out to be useful at different stage of the development process, e.g. comparing the performance of two different models or analysing the behaviour of the same model by tuning different parameters. In this white paper we review a list of the most promising multi-class metrics, we highlight their advantages and disadvantages and show their possible usages during the development of a classification model.},
 author = {Grandini, Margherita and Bagli, Enrico and Visani, Giorgio},
 year = {2020},
 title = {Metrics for Multi-Class Classification: an Overview},
 url = {http://arxiv.org/pdf/2008.05756v1},
 keywords = {Computer Science - Learning;Statistics - Machine Learning},
 journal = {arXiv preprint arXiv:2008.05756},
 file = {2008.05756:Attachments/2008.05756.pdf:application/pdf}
}


@article{GuhaRoy.2016,
 abstract = {Intravascular imaging using ultrasound or optical coherence tomography (OCT) is predominantly used to adjunct clinical information in interventional cardiology. OCT provides high-resolution images for detailed investigation of atherosclerosis-induced thickening of the lumen wall resulting in arterial blockage and triggering acute coronary events. However, the stochastic uncertainty of speckles limits effective visual investigation over large volume of pullback data, and clinicians are challenged by their inability to investigate subtle variations in the lumen topology associated with plaque vulnerability and onset of necrosis. This paper presents a lumen segmentation method using OCT imaging physics-based graph representation of signals and random walks image segmentation approaches. The edge weights in the graph are assigned incorporating OCT signal attenuation physics models. Optical backscattering maxima is tracked along each A-scan of OCT and is subsequently refined using global graylevel statistics and used for initializing seeds for the random walks image segmentation. Accuracy of lumen versus tunica segmentation has been measured on 15 in vitro and 6 in vivo pullbacks, each with 150-200 frames using 1) Cohen's kappa coefficient (0.9786 $\pm$0.0061) measured with respect to cardiologist's annotation and 2) divergence of histogram of the segments computed with Kullback-Leibler (5.17 $\pm$2.39) and Bhattacharya measures (0.56 $\pm$0.28). High segmentation accuracy and consistency substantiates the characteristics of this method to reliably segment lumen across pullbacks in the presence of vulnerability cues and necrotic pool and has a deterministic finite time-complexity. This paper in general also illustrates the development of methods and framework for tissue classification and segmentation incorporating cues of tissue-energy interaction physics in imaging.},
 author = {{Guha Roy}, Abhijit and Conjeti, Sailesh and Carlier, St{\'e}phane G. and Dutta, Pranab K. and Kastrati, Adnan and Laine, Andrew F. and Navab, Nassir and Katouzian, Amin and Sheet, Debdoot},
 year = {2016},
 title = {Lumen Segmentation in Intravascular Optical Coherence Tomography Using Backscattering Tracked and Initialized Random Walks},
 keywords = {Coronary Vessels/diagnostic imaging;Humans;Image Processing, Computer-Assisted/methods;Intravascular imaging;lumen segmentation;optical coherence tomography;Scattering, Radiation;Tomography, Optical Coherence/methods;Ultrasonography, Interventional/methods},
 pages = {606--614},
 volume = {20},
 journal = {IEEE journal of biomedical and health informatics},
 doi = {10.1109/JBHI.2015.2403713},
 file = {Lumen{\_}Segmentation{\_}in{\_}Intravascular{\_}Optical{\_}Coherence{\_}Tomography{\_}Using{\_}Backscattering{\_}Tracked{\_}and{\_}Initialized{\_}Random{\_}Walks:Attachments/Lumen{\_}Segmentation{\_}in{\_}Intravascular{\_}Optical{\_}Coherence{\_}Tomography{\_}Using{\_}Backscattering{\_}Tracked{\_}and{\_}Initialized{\_}Random{\_}Walks.pdf:application/pdf}
}


@article{GuillermoJ.Tearney.2012,
 author = {{Tearney G, Regar E, Akasaka T, et al.}},
 year = {2012},
 title = {Consensus Standards for Acquisition, Measurement, and Reporting of Intravascular Optical Coherence Tomography Studies},
 pages = {1058--1072},
 journal = {Journal of the American College of Cardiology 59},
 doi = {10.1016/j.jacc.2011.09.079},
 file = {Guillermo J Tearney, Evelyn Regar et al 2012 - Consensus Standards for Acquisition:Attachments/Guillermo J Tearney, Evelyn Regar et al 2012 - Consensus Standards for Acquisition.pdf:application/pdf}
}


@article{GULER.2005,
 author = {GULER, N. and UBEYLI, E. and GULER, I.},
 year = {2005},
 title = {Recurrent neural networks employing Lyapunov exponents for EEG signals classification},
 pages = {506--514},
 volume = {29},
 number = {3},
 issn = {09574174},
 journal = {Expert Systems with Applications},
 doi = {10.1016/j.eswa.2005.04.011},
 file = {10.1.1.100.1099:Attachments/10.1.1.100.1099.pdf:application/pdf}
}


@article{HajianTilaki.2013,
 abstract = {This review provides the basic principle and rational for ROC analysis of rating and continuous diagnostic test results versus a gold standard. Derived indexes of accuracy, in particular area under the curve (AUC) has a meaningful interpretation for disease classification from healthy subjects. The methods of estimate of AUC and its testing in single diagnostic test and also comparative studies, the advantage of ROC curve to determine the optimal cut off values and the issues of bias and confounding have been discussed.},
 author = {Hajian-Tilaki, Karimollah},
 year = {2013},
 title = {Receiver Operating Characteristic (ROC) Curve Analysis for Medical Diagnostic Test Evaluation},
 pages = {627--635},
 volume = {4},
 number = {2},
 issn = {2008-6164},
 journal = {Caspian journal of internal medicine},
 file = {Hajian-Tilaki 2013 - Receiver Operating Characteristic ROC Curve:Attachments/Hajian-Tilaki 2013 - Receiver Operating Characteristic ROC Curve.pdf:application/pdf}
}


@article{Halligan.2015,
 abstract = {OBJECTIVES

The objectives are to describe the disadvantages of the area under the receiver operating characteristic curve (ROC AUC) to measure diagnostic test performance and to propose an alternative based on net benefit.

METHODS

We use a narrative review supplemented by data from a study of computer-assisted detection for CT colonography.

RESULTS

We identified problems with ROC AUC. Confidence scoring by readers was highly non-normal, and score distribution was bimodal. Consequently, ROC curves were highly extrapolated with AUC mostly dependent on areas without patient data. AUC depended on the method used for curve fitting. ROC AUC does not account for prevalence or different misclassification costs arising from false-negative and false-positive diagnoses. Change in ROC AUC has little direct clinical meaning for clinicians. An alternative analysis based on net benefit is proposed, based on the change in sensitivity and specificity at clinically relevant thresholds. Net benefit incorporates estimates of prevalence and misclassification costs, and it is clinically interpretable since it reflects changes in correct and incorrect diagnoses when a new diagnostic test is introduced.

CONCLUSIONS

ROC AUC is most useful in the early stages of test assessment whereas methods based on net benefit are more useful to assess radiological tests where the clinical context is known. Net benefit is more useful for assessing clinical impact.

KEY POINTS

 The area under the receiver operating characteristic curve (ROC AUC) measures diagnostic accuracy.  Confidence scores used to build ROC curves may be difficult to assign.  False-positive and false-negative diagnoses have different misclassification costs.  Excessive ROC curve extrapolation is undesirable.  Net benefit methods may provide more meaningful and clinically interpretable results than ROC AUC.},
 author = {Halligan, Steve and Altman, Douglas G. and Mallett, Susan},
 year = {2015},
 title = {Disadvantages of using the area under the receiver operating characteristic curve to assess imaging tests: a discussion and proposal for an alternative approach},
 keywords = {Area Under Curve;Colonography, Computed Tomographic/statistics {\&} numerical data;Diagnostic Imaging/statistics {\&} numerical data;Humans;Reproducibility of Results;ROC Curve;Sensitivity and Specificity},
 pages = {932--939},
 volume = {25},
 number = {4},
 journal = {European radiology},
 doi = {10.1007/s00330-014-3487-0},
 file = {330{\_}2014{\_}Article{\_}3487:Attachments/330{\_}2014{\_}Article{\_}3487.pdf:application/pdf}
}


@misc{HannahRitchie.2018,
 author = {Ritchie, Hannah and Roser, Max},
 year = {2018},
 title = {Causes of Death},
 url = {https://ourworldindata.org/causes-of-death},
 file = {Hannah Ritchie, Max Roser 2018 - Causes of Death:Attachments/Hannah Ritchie, Max Roser 2018 - Causes of Death.pdf:application/pdf}
}


@article{He.12102015,
 abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.  The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
 author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
 year = {2015},
 title = {Deep Residual Learning for Image Recognition},
 url = {http://arxiv.org/pdf/1512.03385v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 pages = {770--778},
 journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
 file = {1512.03385:Attachments/1512.03385.pdf:application/pdf}
}


@article{He.3162016,
 abstract = {Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which makes training easier and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10 (4.62{\%} error) and CIFAR-100, and a 200-layer ResNet on ImageNet. Code is available at: https://github.com/KaimingHe/resnet-1k-layers},
 author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
 year = {2016},
 title = {Identity Mappings in Deep Residual Networks},
 url = {http://arxiv.org/pdf/1603.05027v3},
 keywords = {Computer Science - Computer Vision and Pattern Recognition;Computer Science - Learning},
 pages = {630--645},
 journal = {Computer Vision, ECCV},
 file = {1603.05027:Attachments/1603.05027.pdf:application/pdf}
}


@article{Hee.1995,
 abstract = {To demonstrate optical coherence tomography for high-resolution, noninvasive imaging of the human retina. Optical coherence tomography is a new imaging technique analogous to ultrasound B scan that can provide cross-sectional images of the retina with micrometer-scale resolution.Survey optical coherence tomographic examination of the retina, including the macula and optic nerve head in normal human subjects.Research laboratory.Convenience sample of normal human subjects.Correlation of optical coherence retinal tomographs with known normal retinal anatomy.Optical coherence tomographs can discriminate the cross-sectional morphologic features of the fovea and optic disc, the layered structure of the retina, and normal anatomic variations in retinal and retinal nerve fiber layer thicknesses with 10-\textgreek{m}m depth resolution.Optical coherence tomography is a potentially useful technique for high depth resolution, cross-sectional examination of the fundus.},
 author = {Hee, Michael R. and Izatt, Joseph A. and Swanson, Eric A. and Huang, David and Schuman, Joel S. and Lin, Charles P. and Puliafito, Carmen A. and Fujimoto, James G.},
 year = {1995},
 title = {Optical Coherence Tomography of the Human Retina},
 pages = {325--332},
 volume = {113},
 issn = {0003-9950},
 journal = {Archives of Ophthalmology},
 doi = {10.1001/archopht.1995.01100030081025}
}


@article{HiramG.Bezerra.2009,
 author = {{Hiram G. Bezerra} and {Marco A. Costa} and {Giulio Guagliumi} and {Andrew M. Rollins} and {Daniel I. Simon}},
 year = {2009},
 title = {Intracoronary Optical Coherence Tomography: A Comprehensive Review},
 pages = {1035--1046},
 volume = {2},
 journal = {JACC: Cardiovascular Interventions},
 doi = {10.1016/j.jcin.2009.06.019},
 file = {Hiram G Bezerra, Marco A Costa et al 2009 - Intracoronary Optical Coherence Tomography:Attachments/Hiram G Bezerra, Marco A Costa et al 2009 - Intracoronary Optical Coherence Tomography.pdf:application/pdf}
}


@article{Hoffman.2020,
 author = {Cao, Chang and Chicco, Davide and Hoffman, Michael M.},
 year = {2020},
 title = {The MCC-F1 curve: a performance evaluation technique for binary classification},
 url = {https://arxiv.org/abs/2006.11278},
 volume = {arXiv},
 journal = {Computer and information sciences, I.2.0, 68T05},
 file = {2006.11278:Attachments/2006.11278.pdf:application/pdf}
}


@inproceedings{Hu.2018,
 abstract = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition;2018; ; ;10.1109/CVPR.2018.00745},
 author = {Hu, Jie and Shen, Li and Sun, Gang},
 title = {Squeeze-and-Excitation Networks},
 pages = {7132--7141},
 publisher = {IEEE},
 isbn = {978-1-5386-6420-9},
 booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
 year = {2018},
 doi = {10.1109/CVPR.2018.00745},
 file = {Squeeze-and-Excitation{\_}Networks:Attachments/Squeeze-and-Excitation{\_}Networks.pdf:application/pdf}
}


@article{Huang.1991,
 author = {Huang, David and Swanson, Eric A. and Lin, Charles P. and Schuman, Joel S. and Stinson, William G. and Chang, Warren and Hee, Michael R. and Flotte, Thomas and Gregory, Kenton and Puliafito, Carmen A. and others},
 year = {1991},
 title = {Optical coherence tomography},
 pages = {1178--1181},
 volume = {254},
 number = {5035},
 journal = {science},
 file = {Huang, Swanson et al 1991 - Optical coherence tomography:Attachments/Huang, Swanson et al 1991 - Optical coherence tomography.pdf:application/pdf}
}


@article{Huang.8252016,
 abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet .},
 author = {Huang, Gao and Liu, Zhuang and {van der Maaten}, Laurens and Weinberger, Kilian Q.},
 year = {2016},
 title = {Densely Connected Convolutional Networks},
 url = {http://arxiv.org/pdf/1608.06993v5},
 keywords = {Computer Science - Computer Vision and Pattern Recognition;Computer Science - Learning},
 pages = {4700--4708},
 journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 file = {1608.06993:Attachments/1608.06993.pdf:application/pdf}
}


@article{hussain.2018,
 author = {Hussain, Zeshan and Ginenez, Francisco},
 year = {2018},
 title = {Differential Data Augmentation Techniques for Medical Imaging Classification Tasks},
 journal = {AMIA Annu Symp Proc.},
 file = {2730723:Attachments/2730723.pdf:application/pdf}
}


@article{IbrahemKandel.2020,
 abstract = {Many hyperparameters have to be tuned to have a robust convolutional neural network that will be able to accurately classify images. One of the most important hyperparameters is the batch size, which is the number of images used to train a single forward and backward pass. In this study, the effect of batch size on the performance of convolutional neural networks and the impact of learning rates will be studied for image classification, specifically for medical images. To train the network faster, a VGG16 network with ImageNet weights was used in this experiment. Our results concluded that a higher batch size does not usually achieve high accuracy, and the learning rate and the optimizer used will have a significant impact as well. Lowering the learning rate and decreasing the batch size will allow the network to train better, especially in the case of fine-tuning.},
 author = {Kandel, Ibrahem and Castelli, Mauro},
 year = {2020},
 title = {The effect of batch size on the generalizability of the convolutional neural networks on a histopathology dataset},
 url = {https://www.sciencedirect.com/science/article/pii/S2405959519303455},
 keywords = {Batch size;Convolutional neural networks;deep learning;Image classification;Medical images},
 pages = {312--315},
 volume = {6},
 journal = {ICT Express 6},
 doi = {10.1016/j.icte.2020.04.010},
 file = {Ibrahem Kandel, Mauro Castelli 2020 - The effect of batch size:Attachments/Ibrahem Kandel, Mauro Castelli 2020 - The effect of batch size.pdf:application/pdf}
}


@article{IkKyungJang.2002,
 author = {Jang, Ik-Kyung and Bouma, Brett E. and Kang, Dong-Heon and Park, Seung-Jung and Park, Seong-Wook and Seung, Ki-Bae and Choi, Kyu-Bo and Shishkov, Milen and Schlendorf, Kelly and Pomerantsev, Eugene and Houser, Stuart L. and Aretz, H.Thomas and Tearney, Guillermo J.},
 year = {2002},
 title = {Visualization of coronary atherosclerotic plaques in patients using optical coherence tomography: Comparison with intravascular ultrasound},
 pages = {604--609},
 volume = {39},
 journal = {Journal of the American College of Cardiology},
 doi = {10.1016/S0735-1097(01)01799-5}
}


@misc{Iqbal.2020,
 author = {Iqbal, Haris},
 year = {2020},
 title = {PlotNeuralNet},
 url = {https://github.com/HarisIqbal88/PlotNeuralNet},
 address = {GitHub},
 publisher = {GitHub}
}


@article{JacobYerushalmy.1947,
 author = {Yerushalmy, Jacob},
 year = {1947},
 title = {Statistical Problems in Assessing Methods of Medical Diagnosis, with Special Reference to X-Ray Techniques},
 url = {http://www.jstor.org/stable/4586294},
 pages = {1432--1449},
 volume = {62},
 issn = {00946214},
 journal = {Public Health Reports (1896-1970)}
}


@article{Kalkman.2017,
 author = {Kalkman, J.},
 year = {2017},
 title = {Fourier-Domain Optical Coherence Tomography Signal Analysis and Numerical Modeling},
 pages = {1--16},
 volume = {2017},
 journal = {International Journal of Optics},
 doi = {10.1155/2017/9586067},
 file = {Kalkman 2017 - Fourier-Domain Optical Coherence Tomography Signal:Attachments/Kalkman 2017 - Fourier-Domain Optical Coherence Tomography Signal.pdf:application/pdf}
}


@inproceedings{Ke.2012,
 abstract = {8296-14},
 author = {Ke, Jun and Zhu, Rui and Lam, Edmund Y.},
 title = {Image reconstruction from nonuniformly spaced samples in Fourier domain optical coherence tomography},
 pages = {829610},
 publisher = {SPIE},
 series = {SPIE Proceedings},
 editor = {Bouman, Charles A. and Pollak, Ilya and Wolfe, Patrick J.},
 booktitle = {Computational Imaging X},
 year = {2012},
 doi = {10.1117/12.907331},
 file = {Image{\_}Reconstruction{\_}from{\_}Nonuniformly-spaced{\_}Samp:Attachments/Image{\_}Reconstruction{\_}from{\_}Nonuniformly-spaced{\_}Samp.pdf:application/pdf}
}


@article{KeironOShea.2015,
 author = {{Keiron O'Shea} and {Ryan Nash}},
 year = {2015},
 title = {An Introduction to Convolutional Neural Networks},
 volume = {abs/1511.08458},
 journal = {CoRR},
 file = {Keiron O'Shea, Ryan Nash 2015 - An Introduction to Convolutional Neural:Attachments/Keiron O'Shea, Ryan Nash 2015 - An Introduction to Convolutional Neural.pdf:application/pdf}
}


@article{Kennedy.2014,
 author = {Kennedy, Brendan F. and Kennedy, Kelsey M. and Sampson, David D.},
 year = {2014},
 title = {A Review of Optical Coherence Elastography: Fundamentals, Techniques and Prospects},
 pages = {272--288},
 volume = {20},
 number = {2},
 issn = {1077-260X},
 journal = {IEEE Journal of Selected Topics in Quantum Electronics},
 doi = {10.1109/JSTQE.2013.2291445},
 file = {Kennedy, Kennedy et al 2014 - A Review of Optical Coherence:Attachments/Kennedy, Kennedy et al 2014 - A Review of Optical Coherence.pdf:application/pdf}
}


@article{Ker.2018,
 author = {Ker, Justin and Wang, Lipo and Rao, Jai and Lim, Tchoyoson},
 year = {2018},
 title = {Deep Learning Applications in Medical Image Analysis},
 pages = {9375--9389},
 volume = {6},
 journal = {IEEE Access},
 doi = {10.1109/ACCESS.2017.2788044},
 file = {Ker, Wang et al 2018 - Deep Learning Applications in Medical:Attachments/Ker, Wang et al 2018 - Deep Learning Applications in Medical.pdf:application/pdf}
}


@article{Kermani.2016,
 abstract = {Research Article},
 author = {Kermani, Ali and Taki, Arash and Ayatollahi, Ahmad},
 year = {2016},
 title = {3D Analysis of Thin-Cap Fibroatheromas by an Automatic Graph-Based Approach in Intravascular Optical Coherence Tomography},
 keywords = {3D Reconstruction;Graph;optical coherence tomography;Thin-Cap Fibroatheroma},
 volume = {Inpress},
 issn = {2322-5327},
 journal = {Archives of Cardiovascular Imaging},
 doi = {10.5812/acvi.45187},
 file = {acvi-04-04-45187:Attachments/acvi-04-04-45187.pdf:application/pdf}
}


@article{Kihara.2019,
 abstract = {Importance

As currently used, microperimetry is a burdensome clinical testing modality for testing retinal sensitivity requiring long testing times and trained technicians.

Objective

To create a deep-learning network that could directly estimate function from structure de novo to provide an en face high-resolution map of estimated retinal sensitivity.

Design, Setting, and Participants

A cross-sectional imaging study using data collected between January 1, 2016, and November 30, 2017, from the Natural History Observation and Registry of macular telangiectasia type 2 (MacTel) evaluated 38 participants with confirmed MacTel from 2 centers.

Main Outcomes and Measures

Mean absolute error of estimated compared with observed retinal sensitivity. Observed retinal sensitivity was obtained with fundus-controlled perimetry (microperimetry). Estimates of retinal sensitivity were made with deep-learning models that learned on superpositions of high-resolution optical coherence tomography (OCT) scans and microperimetry results. Those predictions were used to create high-density en face sensitivity maps of the macula. Training, validation, and test sets were segregated at the patient level.

Results

A total of 2499 microperimetry sensitivities were mapped onto 1708 OCT B-scans from 63 eyes of 38 patients (mean [SD] age, 74.3 [9.7] years; 15 men [39.5{\%}]). The numbers of examples for our algorithm were 67899 (103053 after data augmentation) for training, 1695 for validation, and 1212 for testing. Mean absolute error results were 4.51 dB (95{\%} CI, 4.36-4.65 dB) when using linear regression and 3.66 dB (95{\%} CI, 3.53-3.78 dB) when using the LeNet model. Using a 49.9 million-variable deep-learning model, a mean absolute error of 3.36 dB (95{\%} CI, 3.25-3.48 dB) of retinal sensitivity for validation and test was achieved. Correlation showed a high degree of agreement (Pearson correlation r=0.78). By paired Wilcoxon rank sum test, our model significantly outperformed these 2 baseline models (P{\textless}.001).

Conclusions and Relevance

High-resolution en face maps of estimated retinal sensitivities were created in eyes with MacTel. The maps were of unequalled resolution compared with microperimetry and were able to correctly delineate functionally healthy and impaired retina. This model may be useful to monitor structural and functional disease progression and has potential as an objective surrogate outcome measure in investigational trials.},
 author = {Kihara, Yuka and Heeren, Tjebo F. C. and Lee, Cecilia S. and Wu, Yue and Xiao, Sa and Tzaridis, Simone and Holz, Frank G. and {Charbel Issa}, Peter and Egan, Catherine A. and Lee, Aaron Y.},
 year = {2019},
 title = {Estimating Retinal Sensitivity Using Optical Coherence Tomography With Deep-Learning Algorithms in Macular Telangiectasia Type 2},
 keywords = {Aged;Aged, 80 and over;Algorithms;deep learning;Female;Humans;Image Interpretation, Computer-Assisted/methods;Male;Middle Aged;Retina/diagnostic imaging/physiopathology;Retinal Telangiectasis/diagnostic imaging/physiopathology;The JAMA Network;Tomography, Optical Coherence/methods},
 volume = {2},
 journal = {JAMA network open},
 doi = {10.1001/jamanetworkopen.2018.8029},
 file = {kihara{\_}2019{\_}oi{\_}180334:Attachments/kihara{\_}2019{\_}oi{\_}180334.pdf:application/pdf}
}


@article{Kolluru.2018,
 abstract = {We develop neural-network-based methods for classifying plaque types in clinical intravascular optical coherence tomography (IVOCT) images of coronary arteries. A single IVOCT pullback can consist of {\textgreater}500 microscopic-resolution images, creating both a challenge for physician interpretation during an interventional procedure and an opportunity for automated analysis. In the proposed method, we classify each A-line, a datum element that better captures physics and pathophysiology than a voxel, as a fibrous layer followed by calcification (fibrocalcific), a fibrous layer followed by a lipidous deposit (fibrolipidic), or other. For A-line classification, the usefulness of a convolutional neural network (CNN) is compared with that of a fully connected artificial neural network (ANN). A total of 4469 image frames across 48 pullbacks that are manually labeled using consensus labeling from two experts are used for training, evaluation, and testing. A 10-fold cross-validation using held-out pullbacks is applied to assess classifier performance. Noisy A-line classifications are cleaned by applying a conditional random field (CRF) and morphological processing to pullbacks in the en-face view. With CNN (ANN) approaches, we achieve an accuracy of 77.7{\%}$\pm$4.1{\%} ( 79.4{\%}$\pm$2.9{\%} ) for fibrocalcific, 86.5{\%}$\pm$2.3{\%} ( 83.4{\%}$\pm$2.6{\%} ) for fibrolipidic, and 85.3{\%}$\pm$2.5{\%} ( 82.4{\%}$\pm$2.2{\%} ) for other, across all folds following CRF noise cleaning. The results without CRF cleaning are typically reduced by 10{\%} to 15{\%}. The enhanced performance of the CNN was likely due to spatial invariance of the convolution operation over the input A-line. The predicted en-face classification maps of entire pullbacks agree favorably to the annotated counterparts. In some instances, small error regions are actually hard to call when re-examined by human experts. Even in worst-case pullbacks, it can be argued that the results will not negatively impact usage by physicians, as there is a preponderance of correct calls.},
 author = {Kolluru, Chaitanya and Prabhu, David and Gharaibeh, Yazan and Bezerra, Hiram and Guagliumi, Giulio and Wilson, David},
 year = {2018},
 title = {Deep neural networks for A-line-based plaque classification in coronary intravascular optical coherence tomography images},
 pages = {044--504},
 volume = {5},
 issn = {2329-4302},
 journal = {Journal of medical imaging (Bellingham, Wash.)},
 doi = {10.1117/1.JMI.5.4.044504},
 file = {044504{\_}1:Attachments/044504{\_}1.pdf:application/pdf}
}


@article{KostadinkaBizheva.2017,
 abstract = {Corneal degenerative conditions such as keratoconus (KC) cause progressive damage to the anterior corneal tissue and eventually severely compromise visual acuity. The ability to visualize corneal tissue damage in-vivo at cellular or sub-cellular level at different stages of development of KC and other corneal diseases, can aid the early diagnostics as well as the development of more effective treatment approaches for various corneal pathologies, including keratoconus. Here, we present the optical design of an optical coherence tomography system that can achieve 0.95 m axial resolution in biological tissue and provide test results for the system's spatial resolution and sensitivity. Corneal images acquired in-vivo with this system from healthy and keratoconic human subjects reveal the cellular and sub-cellular structure of the corneal epithelium, as well as the normal and abnormal structure of the Bowman's membrane and the anterior corneal stroma.},
 author = {{Kostadinka Bizheva} and {Bingyao Tan} and {Benjamin MacLelan} and {Olivera Kralj} and {Mojtaba Hajialamdari} and {Denise Hileeto} and {Luigina Sorbara}},
 year = {2017},
 title = {Sub-micrometer axial resolution OCT for in-vivo imaging of the cellular structure of healthy and keratoconic human corneas},
 keywords = {devices;Full field optical coherence tomography;Image processing;Imaging systems;Medical imaging;Ophthalmic optics;optical coherence tomography;optical imaging;Spatial resolution;Visual acuity},
 pages = {800--812},
 volume = {8},
 journal = {Biomed. Opt. Express},
 doi = {10.1364/BOE.8.000800},
 file = {Kostadinka Bizheva, Bingyao Tan et al 2017 - Sub-micrometer axial resolution OCT:Attachments/Kostadinka Bizheva, Bingyao Tan et al 2017 - Sub-micrometer axial resolution OCT.pdf:application/pdf}
}


@article{Krizhevsky.2017,
 abstract = {Neural Information Processing Systems http://nips.cc/},
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
 year = {2017},
 title = {ImageNet classification with deep convolutional neural networks},
 pages = {84--90},
 volume = {60},
 number = {6},
 issn = {0001-0782},
 journal = {Communications of the ACM},
 doi = {10.1145/3065386},
 file = {NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper:Attachments/NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf:application/pdf}
}


@article{KumarArvind.2020,
 author = {{Kumar Arvind} and {Sodhi Sartaj Singh}},
 year = {2020},
 title = {Comparative Analysis of Gaussian Filter, Median Filter and Denoise Autoenocoder},
 pages = {45--51},
 journal = {2020 7th International Conference 2020},
 doi = {10.23919/INDIACom49435.2020.9083712}
}


@article{KunGao.2019,
 abstract = {Background and objective

Quantitative assessment of subretinal fluid in spectral domain optical coherence tomography (SD-OCT) images is crucial for the diagnosis of central serous chorioretinopathy. For the subretinal fluid segmentation, the traditional methods need to segment retinal layers and then segment subretinal fluid. The layer segmentation has a high influence on subretinal fluid segmentation, so we aim to develop a deep learning model to segment subretinal fluid automatically without layer segmentation.

Methods

In this paper, we propose a novel image-to-image double-branched and area-constraint fully convolutional networks (DA-FCN) for segmenting subretinal fluid in SD-OCT images. Firstly, the dataset is extended by mirroring image, which helps to overcome the over-fitting problem in the training stage. Then, double-branched structures are designed to learn the shallow coarse and deep representations from the SD-OCT images. DA-FCN model is directly trained using the image and corresponding pixel-based ground truth. Finally, we introduce a novel supervision mechanism by jointing the area loss LA with the softmax loss LS to learn more representative features.

Results

The testing dataset with 52 SD-OCT volumes from 35 eyes of 35 patients is used for the evaluation of the proposed algorithm based on the cross-validation method. For the three criterions, including the true positive volume fraction, dice similarity coefficient, and positive predicative value, our method can obtain the results of (1) 94.3, 95.3, and 96.4 for dataset 1; (2) 97.3, 95.3, and 93.4 for dataset 2; (3) 93.0, 92.8, and 92.8 for dataset 3; (4) 89.7, 90.1, and 92.6 for dataset 4.

Conclusion

In this work, we propose a novel fully convolutional network for the automatic segmentation of the subretinal fluid. By constructing the double branched structures and area constraint term, our method shows higher segmentation accuracy without layer segmentation compared with other methods.},
 author = {Gao, Kun and Niu, Sijie and Ji, Zexuan and Wu, Menglin and Chen, Qiang and Xu, Rongbin and Yuan, Songtao and Fan, Wen and Chen, Yuehui and Dong, Jiwen},
 year = {2019},
 title = {Double-branched and area-constraint fully convolutional networks for automated serous retinal detachment segmentation in SD-OCT images},
 url = {https://www.sciencedirect.com/science/article/pii/S0169260718318327},
 keywords = {area-constraint fully convolutional networks;Central serous chorioretinopathy;Double-branched;Medical image segmentation;Spectral domain optical coherence tomography},
 pages = {69--80},
 volume = {176},
 issn = {0169-2607},
 journal = {Computer Methods and Programs in Biomedicine},
 doi = {10.1016/j.cmpb.2019.04.027}
}


@article{Kuwayama.2019,
 abstract = {Purpose

Although optical coherence tomography (OCT) is essential for ophthalmologists, reading of findings requires expertise. The purpose of this study is to test deep learning with image augmentation for automated detection of chorioretinal diseases.

Methods

A retina specialist diagnosed 1,200 OCT images. The diagnoses involved normal eyes (n=570) and those with wet age-related macular degeneration (AMD) (n=136), diabetic retinopathy (DR) (n=104), epiretinal membranes (ERMs) (n=90), and another 19 diseases. Among them, 1,100 images were used for deep learning training, augmented to 59,400 by horizontal flipping, rotation, and translation. The remaining 100 images were used to evaluate the trained convolutional neural network (CNN) model.

Results

Automated disease detection showed that the first candidate disease corresponded to the doctor's decision in 83 (83{\%}) images and the second candidate disease in seven (7{\%}) images. The precision and recall of the CNN model were 0.85 and 0.97 for normal eyes, 1.00 and 0.77 for wet AMD, 0.78 and 1.00 for DR, and 0.75 and 0.75 for ERMs, respectively. Some of rare diseases such as Vogt-Koyanagi-Harada disease were correctly detected by image augmentation in the CNN training.

Conclusion

Automated detection of macular diseases from OCT images might be feasible using the CNN model. Image augmentation might be effective to compensate for a small image number for training.},
 author = {Kuwayama, Soichiro and Ayatsuka, Yuji and Yanagisono, Daisuke and Uta, Takaki and Usui, Hideaki and Kato, Aki and Takase, Noriaki and Ogura, Yuichiro and Yasukawa, Tsutomu},
 year = {2019},
 title = {Automated Detection of Macular Diseases by Optical Coherence Tomography and Artificial Intelligence Machine Learning of Optical Coherence Tomography Images},
 volume = {2019},
 issn = {2090-004X},
 journal = {Journal of ophthalmology},
 doi = {10.1155/2019/6319581},
 file = {6319581:Attachments/6319581.pdf:application/pdf}
}


@article{Lang.2018,
 author = {Lang, Andrew and Carass, Aaron and Jedynak, Bruno M. and Solomon, Sharon D. and Calabresi, Peter A. and Prince, Jerry L.},
 year = {2018},
 title = {Intensity inhomogeneity correction of SD-OCT data using macular flatspace},
 pages = {85--97},
 volume = {43},
 journal = {Medical image analysis},
 file = {Lang, Carass et al 2018 - Intensity inhomogeneity correction of SD-OCT:Attachments/Lang, Carass et al 2018 - Intensity inhomogeneity correction of SD-OCT.pdf:application/pdf}
}


@article{LeCun.2015,
 author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
 year = {2015},
 title = {Deep Learning},
 pages = {436--444},
 volume = {521},
 journal = {Nature},
 doi = {10.1038/nature14539},
 file = {LeCun, Bengio et al 2015 - Deep Learning:Attachments/LeCun, Bengio et al 2015 - Deep Learning.pdf:application/pdf}
}


@inproceedings{Liu.2018,
 author = {Liu, Yi-Chieh and Yang, Hao-Hsiang and Yang, C-H Huck and Huang, Jia-Hong and Tian, Meng and Morikawa, Hiromasa and Tsai, Yi-Chang James and Tegner, Jesper},
 title = {Synthesizing new retinal symptom images by multiple generative models},
 pages = {235--250},
 booktitle = {Asian Conference on Computer Vision},
 year = {2018},
 file = {Liu, Yang et al 2018 - Synthesizing new retinal symptom images:Attachments/Liu, Yang et al 2018 - Synthesizing new retinal symptom images.pdf:application/pdf}
}


@article{Long.2015,
 author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
 year = {2015},
 title = {Fully Convolutional Networks for Semantic Segmentation},
 journal = {IEEE Conference},
 file = {Long, Shelhamer et al 2015 - Fully Convolutional Networks for Semantic:Attachments/Long, Shelhamer et al 2015 - Fully Convolutional Networks for Semantic.pdf:application/pdf}
}


@article{Lu.2012,
 abstract = {Intravascular optical coherence tomography (iOCT) is being used to assess viability of new coronary artery stent designs. We developed a highly automated method for detecting stent struts and measuring tissue coverage. We trained a bagged decision trees classifier to classify candidate struts using features extracted from the images. With 12 best features identified by forward selection, recall (precision) were 90{\%}-94{\%} (85{\%}-90{\%}). Including struts deemed insufficiently bright for manual analysis, precision improved to 94{\%}. Strut detection statistics approached variability of manual analysis. Differences between manual and automatic area measurements were 0.12 $\pm$ 0.20 mm(2) and 0.11 $\pm$ 0.20 mm(2) for stent and tissue areas, respectively. With proposed algorithms, analyst time per stent should significantly reduce from the 6-16 hours now required.},
 author = {Lu, Hong and Gargesha, Madhusudhana and Wang, Zhao and Chamie, Daniel and Attizzani, Guilherme F. and Kanaya, Tomoaki and Ray, Soumya and Costa, Marco A. and Rollins, Andrew M. and Bezerra, Hiram G. and Wilson, David L.},
 year = {2012},
 title = {Automatic stent detection in intravascular OCT images using bagged decision trees},
 pages = {2809--2824},
 volume = {3},
 issn = {2156-7085},
 journal = {Biomedical optics express},
 doi = {10.1364/BOE.3.002809},
 file = {boe-3-11-2809:Attachments/boe-3-11-2809.pdf:application/pdf}
}


@article{Maas.2013,
 author = {Maas, Andrew L. and Hannun, Awni Y. and Ng, Andrew Y. and others},
 year = {w2013},
 title = {Rectifier nonlinearities improve neural network acoustic models},
 journal = {Proc. icml 30},
 file = {Maas, Hannun et al 2013 - Rectifier nonlinearities improve neural network:Attachments/Maas, Hannun et al 2013 - Rectifier nonlinearities improve neural network.pdf:application/pdf}
}


@book{Mahmood.2018,
 author = {Mahmood, Syed Jafar},
 year = {2018},
 title = {Effects of Pre-Processed Training Data on Convolutional Neural Network's Training Accuracy where Training Dataset is Small},
 url = {https://www.grin.com/document/443889},
 publisher = {GRIN}
}


@article{Majib.2021,
 abstract = {IEEE Access;2021;9; ;10.1109/ACCESS.2021.3105874},
 author = {Majib, Mohammad Shahjahan and Rahman, Md. Mahbubur and Sazzad, T. M. Shahriar and Khan, Nafiz Imtiaz and Dey, Samrat Kumar},
 year = {2021},
 title = {VGG-SCNet: A VGG Net-Based Deep Learning Framework for Brain Tumor Detection on MRI Images},
 pages = {116942--116952},
 volume = {9},
 journal = {IEEE Access},
 doi = {10.1109/ACCESS.2021.3105874},
 file = {VGG-SCNet{\_}A{\_}VGG{\_}Net-Based{\_}Deep{\_}Learning{\_}Framework{\_}for{\_}Brain{\_}Tumor{\_}Detection{\_}on{\_}MRI{\_}Images:Attachments/VGG-SCNet{\_}A{\_}VGG{\_}Net-Based{\_}Deep{\_}Learning{\_}Framework{\_}for{\_}Brain{\_}Tumor{\_}Detection{\_}on{\_}MRI{\_}Images.pdf:application/pdf}
}


@article{Mari.2013,
 abstract = {PURPOSE

We improved the visibility of the lamina cribrosa (LC), including its posterior boundary, in optical coherence tomography (OCT) images of the human optic nerve head (ONH).

METHODS

An adaptive compensation algorithm was developed to overcome a limitation of our standard compensation algorithm, that is the overamplification of noise at high depth. Such limitation currently hampers our ability to distinguish the posterior LC boundary. In adaptive compensation, standard compensation operations are performed until an energy threshold is reached, at which stage the compensation process is stopped to limit noise overamplification in the deeper portion of the OCT image. The performance of adaptive compensation was compared to that of standard compensation using OCT images of 5 human ONHs.

RESULTS

Adaptive compensation significantly reduced the intralayer contrast (a measure of pixel intensity uniformity) in the deeper portion of the OCT images (from 0.62 $\pm$ 0.11-0.30 $\pm$ 0.03, P {\textless} 0.001), indicating successful removal of noise overamplification. Furthermore, adaptive compensation significantly increased the interlayer contrast (a measure of boundary visibility) across the posterior LC boundary (from 0.29 $\pm$ 0.13-0.61 $\pm$ 0.21, P {\textless} 0.001), indicating improved posterior LC boundary visibility.

CONCLUSIONS

Adaptive compensation provided significant improvement compared to standard compensation by eliminating noise overamplification at high depth and improving the visibility of the posterior LC boundary. These improvements were performed while maintaining all other benefits of compensation, such as shadow removal and contrast enhancement. Adaptive compensation will help further our efforts to characterize in vivo ONH biomechanics for the diagnosis and monitoring of glaucoma.},
 author = {Mari, Jean Martial and Strouthidis, Nicholas G. and Park, Sung Chul and Girard, Micha{\"e}l J. A.},
 year = {2013},
 title = {Enhancement of lamina cribrosa visibility in optical coherence tomography images using adaptive compensation},
 keywords = {Algorithms;Humans;Image Processing, Computer-Assisted;Optic Disk/anatomy {\&} histology;Tomography, Optical Coherence/methods},
 pages = {2238--2247},
 volume = {54},
 number = {3},
 journal = {Investigative ophthalmology {\&} visual science},
 doi = {10.1167/iovs.12-11327},
 file = {i1552-5783-54-3-2238:Attachments/i1552-5783-54-3-2238.pdf:application/pdf}
}


@article{MartinA.Tanner.1987,
 author = {Tanner, Martin A. and {Wong, Wing   Hung}},
 year = {1987},
 title = {The Calculation of Posterior Distributions by Data Augmentation},
 pages = {528--540},
 volume = {82},
 journal = {Journal of the American Statistical Association},
 doi = {10.1080/01621459.1987.10478458}
}


@article{MaximilianNeidhardt.2020,
 author = {{Maximilian Neidhardt} and {Marcel Bengs} and {Sarah Latus} and {Matthias Schl{\"u}ter} and {Thore Saathoff} and {A. Schlaefer}},
 year = {2020},
 title = {Deep Learning for High Speed Optical Coherence Elastography},
 pages = {1583--1586},
 journal = {2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)},
 file = {Maximilian Neidhardt, Marcel Bengs et al 2020 - Deep Learning for High Speed:Attachments/Maximilian Neidhardt, Marcel Bengs et al 2020 - Deep Learning for High Speed.pdf:application/pdf}
}


@article{MichaelPircher.2004,
 abstract = {We present three dimensional images of backscattered intensity, and to the best of our knowledge, the first 3D-images of retardation and fast axis orientation of human skin in vivo. The images were recorded with a phase resolved, polarization sensitive optical coherence tomography (OCT) system which is based on a fast transversal scanning of the sample. The three dimensional data sets were obtained by recording several en face images at different depths within the sample. Intensity and retardation images are combined to a 4 dimensional animation to enhance the visualization of the three dimensional data set. The three dimensional information enables a more accurate interpretation of the structural and birefringence information as compared to 2 dimensional B-scans. Birefringence properties of different skin regions are presented and discussed.},
 author = {{Michael Pircher} and {Erich Goetzinger} and {Rainer Leitgeb} and {Christoph K. Hitzenberger}},
 year = {2004},
 title = {Three dimensional polarization sensitive OCT of human skin in vivo},
 keywords = {biological imaging;Form birefringence;In vivo imaging;optical coherence tomography;Phase measurement;Polarization-selective devices;Three dimensional imaging},
 pages = {3236--3244},
 volume = {12},
 number = {14},
 journal = {Opt. Express},
 doi = {10.1364/OPEX.12.003236},
 file = {Michael Pircher, Erich Goetzinger et al 2004 - Three dimensional polarization sensitive OCT:Attachments/Michael Pircher, Erich Goetzinger et al 2004 - Three dimensional polarization sensitive OCT.pdf:application/pdf}
}


@article{MingxingTan.2019,
 author = {{Mingxing Tan} and {Quoc V. Le}},
 year = {2019},
 title = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
 volume = {abs/1905.11946},
 journal = {CoRR},
 file = {Mingxing Tan, Quoc V Le 2019 - EfficientNet:Attachments/Mingxing Tan, Quoc V Le 2019 - EfficientNet.pdf:application/pdf}
}


@proceedings{Mira.1995,
 year = {1995},
 title = {From Natural to Artificial Neural Computation},
 address = {Berlin, Heidelberg},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-540-49288-7},
 editor = {Mira, Jos{\'e} and Sandoval, Francisco}
}


@proceedings{Mori.2013,
 year = {2013},
 title = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2013},
 address = {Berlin, Heidelberg},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-642-40763-5},
 editor = {Mori, Kensaku and Sakuma, Ichiro and Sato, Yoshinobu and Barillot, Christian and Navab, Nassir}
}


@article{NationalVitalStatisticsReports.2017,
 abstract = {National Vital Statistics Reports Volume 68, Number 6, June 24, 2019, Deaths: Leading Causes for 2017},
 author = {Heron, Melonie},
 year = {2017},
 title = {Deaths: Leading Causes for 2017: National Vital Statistics Reports},
 keywords = {racial and ethnic differences;sex differences;vital statistics},
 journal = {National Vital Statistics Reports 68},
 file = {cdc{\_}79488{\_}DS1:Attachments/cdc{\_}79488{\_}DS1.pdf:application/pdf}
}


@article{Neidhardt.2021,
 abstract = {PURPOSE

Elasticity of soft tissue provides valuable information to physicians during treatment and diagnosis of diseases. A number of approaches have been proposed to estimate tissue stiffness from the shear wave velocity. Optical coherence elastography offers a particularly high spatial and temporal resolution. However, current approaches typically acquire data at different positions sequentially, making it slow and less practical for clinical application.

METHODS

We propose a new approach for elastography estimations using a fast imaging device to acquire small image volumes at rates of 831 Hz. The resulting sequence of phase image volumes is fed into a 4D convolutional neural network which handles both spatial and temporal data processing. We evaluate the approach on a set of image data acquired for gelatin phantoms of known elasticity.

RESULTS

Using the neural network, the gelatin concentration of unseen samples was predicted with a mean error of 0.65 $\pm$ 0.81 percentage points from 90 subsequent volumes of phase data only. We achieve a data acquisition and data processing time of under 12 ms and 22 ms, respectively.

CONCLUSIONS

We demonstrate direct volumetric optical coherence elastography from phase image data. The approach does not rely on particular stimulation or sampling sequences and allows the estimation of elastic tissue properties of up to 40 Hz.},
 author = {Neidhardt, M. and Bengs, M. and Latus, S. and Schl{\"u}ter, M. and Saathoff, T. and Schlaefer, A.},
 year = {2021},
 title = {4D deep learning for real-time volumetric optical coherence elastography},
 keywords = {Convolutional neuronal networks;deep learning;Elasticity Imaging Techniques/methods;Humans;Optical coherence elastography;Phantoms, Imaging;Real-time imaging;Tomography, Optical Coherence/methods},
 pages = {23--27},
 volume = {16},
 number = {1},
 journal = {International journal of computer assisted radiology and surgery},
 doi = {10.1007/s11548-020-02261-5},
 file = {11548{\_}2020{\_}Article{\_}2261:Attachments/11548{\_}2020{\_}Article{\_}2261.pdf:application/pdf}
}


@misc{Neutelings.2021,
 author = {Neutelings, Izaak},
 year = {2021},
 title = {Neural networks: Graphics with TikZ in LateX},
 url = {https://tikz.net/neural_networks/#full_code},
 urldate = {11.02.2022},
 publisher = {TikZ.net}
}


@book{Nielsen.2015,
 author = {Nielsen, Michael A.},
 year = {2015},
 title = {Neural Networks and Deep Learning},
 url = {http://neuralnetworksanddeeplearning.com/},
 publisher = {{Determination Press}},
 file = {Nielsen 2015 - Neural Networks and Deep Learning:Attachments/Nielsen 2015 - Neural Networks and Deep Learning.pdf:application/pdf}
}


@misc{Odaibo.2182019,
 abstract = {We report, to our knowledge, the first end-to-end application of Generative Adversarial Networks (GANs) towards the synthesis of Optical Coherence Tomography (OCT) images of the retina. Generative models have gained recent attention for the increasingly realistic images they can synthesize, given a sampling of a data type. In this paper, we apply GANs to a sampling distribution of OCTs of the retina. We observe the synthesis of realistic OCT images depicting recognizable pathology such as macular holes, choroidal neovascular membranes, myopic degeneration, cystoid macular edema, and central serous retinopathy amongst others. This represents the first such report of its kind. Potential applications of this new technology include for surgical simulation, for treatment planning, for disease prognostication, and for accelerating the development of new drugs and surgical procedures to treat retinal disease.},
 author = {Odaibo, Stephen G. and D, M. and S, M.},
 date = {2/18/2019},
 title = {Generative Adversarial Networks Synthesize Realistic OCT Images of the  Retina},
 url = {http://arxiv.org/pdf/1902.06676v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition;Computer Science - Learning},
 file = {1902.06676:Attachments/1902.06676.pdf:application/pdf}
}


@article{Oldenburg.2007,
 author = {Oldenburg, Amy L. and Xu, Chenyang and Boppart, Stephen A.},
 year = {2007},
 title = {Spectroscopic Optical Coherence Tomography and Microscopy},
 pages = {1629--1640},
 volume = {13},
 number = {6},
 issn = {1077-260X},
 journal = {IEEE Journal of Selected Topics in Quantum Electronics},
 doi = {10.1109/JSTQE.2007.910292},
 file = {Spectroscopic{\_}Optical{\_}Coherence{\_}Tomography{\_}and{\_}Microscopy:Attachments/Spectroscopic{\_}Optical{\_}Coherence{\_}Tomography{\_}and{\_}Microscopy.pdf:application/pdf}
}


@inproceedings{OliveiraWillianDihansterG.de.2020,
 author = {{Oliveira, Willian Dihanster G. de} and Penatti, Ot{\'a}vio A. B. and Berton, Lilian},
 title = {A comparison of graph-based semi-supervised learning for data augmentation},
 pages = {264--271},
 booktitle = {2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)},
 year = {2020},
 doi = {10.1109/SIBGRAPI51738.2020.00043},
 file = {Oliveira, Willian Dihanster G de, Penatti et al 2020 - A comparison of graph-based semi-supervised:Attachments/Oliveira, Willian Dihanster G de, Penatti et al 2020 - A comparison of graph-based semi-supervised.pdf:application/pdf}
}


@misc{OxfordUniversityPress.2022,
 author = {{Oxford University Press.}},
 editor = {{Oxford University Press.}},
 year = {2022},
 title = {Definition of Heat Map},
 url = {https://www.lexico.com/en/definition/heat_map},
 urldate = {14.04.2022}
}


@article{Paszke.2019,
 author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
 year = {2019},
 title = {Pytorch: An imperative style, high-performance deep learning library},
 journal = {Advances in neural information processing systems 32},
 file = {Paszke, Gross et al 2019 - Pytorch An imperative style:Attachments/Paszke, Gross et al 2019 - Pytorch An imperative style.pdf:application/pdf}
}


@article{Pedregosa.2011,
 author = {Pedregosa, Fabian and Varoquaux, Gael and Gramford, Alexandre and Michel, Vincent and Thirion, Bertrand},
 year = {2011},
 title = {Scikit-learn: Machine Learning in Python},
 journal = {Journal ofMachine Learning Research 12},
 file = {pedregosa11a:Attachments/pedregosa11a.pdf:application/pdf}
}


@article{PeterFlach.2015,
 abstract = {Neural Information Processing Systems http://nips.cc/},
 author = {{Peter Flach} and {Meelis Kull}},
 year = {2015},
 title = {Precision-Recall-Gain Curves: PR Analysis Done Right},
 journal = {Advances in Neural Information Processing Systems 28 (NIPS 2015)},
 file = {NIPS-2015-precision-recall-gain-curves-pr-analysis-done-right-Paper:Attachments/NIPS-2015-precision-recall-gain-curves-pr-analysis-done-right-Paper.pdf:application/pdf}
}


@article{Powers.2008,
 author = {Powers, David Martin},
 year = {2008},
 title = {Minors as miners: Modelling and evaluating ontological and linguistic learning},
 file = {Powers 2008 - Minors as miners:Attachments/Powers 2008 - Minors as miners.pdf:application/pdf}
}


@article{Powers.2008b,
 author = {Powers, David Martin},
 year = {2008},
 title = {Minors as miners: Modelling and evaluating ontological and linguistic learning}
}


@misc{PyTorchContributors.2019,
 author = {{PyTorch Contributors}},
 year = {2019},
 title = {PYTORCH DOCUMENTATION: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.},
 url = {https://pytorch.org/docs/stable/index.html},
 urldate = {2022}
}


@article{Raghavan.1989,
 author = {Raghavan, Vijay and Bollmann, Peter and Jung, Gwang S.},
 year = {1989},
 title = {A critical investigation of recall and precision as measures of retrieval system performance},
 pages = {205--229},
 volume = {7},
 number = {3},
 issn = {1046-8188},
 journal = {ACM Transactions on Information Systems},
 doi = {10.1145/65943.65945},
 file = {10.1.1.160.5087:Attachments/10.1.1.160.5087.pdf:application/pdf}
}


@misc{Reading.2019,
 author = {Reading, Darren},
 year = {2019},
 title = {tex-neural-network},
 url = {https://github.com/dreading/tex-neural-network},
 address = {GitHub},
 urldate = {15.04.2022},
 publisher = {GitHub}
}


@misc{Riebesell.2022,
 author = {Riebesell, Janosh},
 year = {2022},
 title = {Random Tikz Collection: 107 standalone TikZ images, mostly about physics and machine learning.},
 url = {https://tikz.netlify.app},
 urldate = {13.04.2022}
}


@article{RighabHamdan.2012,
 abstract = {Summary

Optical coherence tomography is a new endocoronary imaging modality employing near infrared light, with very high axial resolution. We will review the physical principles, including the old time domain and newer Fourier domain generations, clinical applications, controversies and perspectives of optical coherence tomography.

R{\'e}sum{\'e}

La tomographie par coh{\'e}rence optique est une modalit{\'e} d'imagerie r{\'e}cente endocoronaire utilisant la lumi{\`e}re infrarouge, caract{\'e}ris{\'e}e par une haute r{\'e}solution. Dans cet article, on discute les principes physiques en discutant l'ancienne et la nouvelle g{\'e}n{\'e}ration de tomographie par coh{\'e}rence optique, time domain et Fourier domain respectivement.},
 author = {Righab, Hamdan and Ricardo, Garcia Gonzalez and Said, Ghostine and Christophe, Caussin},
 year = {2012},
 title = {Optical coherence tomography: From physical principles to clinical applications},
 url = {https://www.sciencedirect.com/science/article/pii/S1875213612001490},
 keywords = {Acute coronary syndrome;Angioplastie percutan{\'e}e;Ath{\'e}roscl{\'e}rose;atherosclerosis;optical coherence tomography;Percutaneous angioplasty;Syndrome coronaire aigu;Tomographie par coh{\'e}rence optique},
 pages = {529--534},
 journal = {Archives of Cardiovascular Diseases 105},
 doi = {10.1016/j.acvd.2012.02.012},
 file = {Righab Hamdan, Ricardo Garcia Gonzalez et al 2012 - Optical coherence tomography:Attachments/Righab Hamdan, Ricardo Garcia Gonzalez et al 2012 - Optical coherence tomography.pdf:application/pdf}
}


@article{Ruini.2021,
 abstract = {BACKGROUND

Basal cell carcinoma (BCC) is the most common skin cancer in the general population. Treatments vary from Mohs surgery to topical therapy, depending on the subtype. Dermoscopy, reflectance confocal microscopy (RCM) and optical coherence tomography (OCT) have gained a foothold in daily clinical practice to optimize diagnosis and subtype-oriented treatment. The new technique of line-field confocal OCT (LC-OCT) allows imaging at high resolution and depth, but its use has not yet been investigated in larger studies.

AIM

To evaluate the main LC-OCT criteria for the diagnosis and subtyping of BCC compared with histopathology, OCT and RCM.

METHODS

In total, 52 histopathologically confirmed BCCs were evaluated for imaging criteria. Their frequency, predictive values and ROC curves were calculated. A multinominal regression with stepwise variables selection to distinguish BCC subtypes was performed.

RESULTS

Nodular BCCs were mainly characterized by atypical keratinocytes, altered dermoepidermal junction (DEJ), tumour nests in the dermis, dark clefting, prominent vascularization and white hyper-reflective stroma. Superficial BCCs showed a thickening of the epidermis due to a series of tumour lobules with clear connection to the DEJ (string of pearls pattern). Infiltrative BCCs were characterized by elongated hyporeflective tumour strands, surrounded by bright collagen (shoal of fish pattern). The overall BCC subtype agreement between LC-OCT and conventional histology was 90.4{\%} (95{\%} CI 79.0-96.8).

CONCLUSION

LC-OCT allows noninvasive, real-time identification of BCCs and their subtypes in vertical, horizontal and three-dimension mode compared with histology, RCM and OCT. Further larger studies are needed to better explore the clinical applications of this promising device.},
 author = {Ruini, C. and Schuh, S. and Gust, C. and Kendziora, B. and Frommherz, L. and French, L. E. and Hartmann, D. and Welzel, J. and Sattler, E.},
 year = {2021},
 title = {Line-field optical coherence tomography: in vivo diagnosis of basal cell carcinoma subtypes compared with histopathology},
 keywords = {Aged;Carcinoma, Basal Cell/classification/diagnostic imaging/pathology;Dermoscopy;Diagnosis, Differential;Female;Humans;Male;Prospective Studies;Sensitivity and Specificity;Skin Neoplasms/classification/diagnostic imaging/pathology;Tomography, Optical Coherence/methods},
 pages = {1471--1481},
 volume = {46},
 journal = {Clinical and experimental dermatology},
 doi = {10.1111/ced.14762},
 file = {Ruini, Schuh et al 2021 - Line-field optical coherence tomography:Attachments/Ruini, Schuh et al 2021 - Line-field optical coherence tomography.pdf:application/pdf}
}


@article{S.H.Yun.2004,
 abstract = {We describe results of theoretical and experimental investigations of artifacts that can arise in spectral-domain optical coherence tomography (SD-OCT) and optical frequency domain imaging (OFDI) as a result of sample or probe beam motion. While SD-OCT and OFDI are based on similar spectral interferometric principles, the specifics of motion effects are quite different because of distinct signal acquisition methods. These results provide an understanding of motion artifacts such as signal fading, spatial distortion and blurring, and emphasize the need for fast image acquisition in biomedical applications.},
 author = {{S. H. Yun} and {G. J. Tearney} and {J. F. de Boer} and {B. E. Bouma}},
 year = {2004},
 title = {Motion artifacts in optical coherence tomography with frequency-domain ranging},
 keywords = {biological imaging;Image quality;Imaging systems;Imaging techniques;Medical;Medical imaging;optical coherence tomography;Spatial frequency},
 pages = {2977--2998},
 volume = {12},
 number = {13},
 journal = {Opt. Express},
 doi = {10.1364/OPEX.12.002977},
 file = {S H Yun, G J Tearney et al 2004 - Motion artifacts in optical coherence:Attachments/S H Yun, G J Tearney et al 2004 - Motion artifacts in optical coherence.pdf:application/pdf}
}


@article{Sahoo.2021,
 abstract = {IEEE Access; ;PP;99;10.1109/ACCESS.2021.3135658},
 author = {Sahoo, Karam Kumar and Dutta, Ishan and Ijaz, Muhammad Fazal and Wozniak, Marcin and Singh, Pawan Kumar},
 year = {2021},
 title = {TLEFuzzyNet: Fuzzy Rank-Based Ensemble of Transfer Learning Models for Emotion Recognition From Human Speeches},
 pages = {166518--166530},
 volume = {9},
 journal = {IEEE Access},
 doi = {10.1109/ACCESS.2021.3135658},
 file = {TLEFuzzyNet{\_}Fuzzy{\_}Rank-Based{\_}Ensemble{\_}of{\_}Transfer{\_}:Attachments/TLEFuzzyNet{\_}Fuzzy{\_}Rank-Based{\_}Ensemble{\_}of{\_}Transfer{\_}.pdf:application/pdf}
}


@article{SatishKumarDubey.2008,
 abstract = {We demonstrate simultaneous topography and tomography of latent fingerprints using full-field swept-source optical coherence tomography (OCT). The swept-source OCT system comprises a superluminescent diode (SLD) as broad-band light source, an acousto-optic tunable filter (AOTF) as frequency tuning device, and a compact, nearly common-path interferometer. Both the amplitude and the phase map of the interference fringe signal are reconstructed. Optical sectioning of the latent fingerprint sample is obtained by selective Fourier filtering and the topography is retrieved from the phase map. Interferometry, selective filtering, low coherence and hence better resolution are some of the advantages of the proposed system over the conventional fingerprint detection techniques. The present technique is non-invasive in nature and does not require any physical or chemical processing. Therefore, the quality of the sample does not alter and hence the same fingerprint can be used for other types of forensic test. Exploitation of low-coherence interferometry for fingerprint detection itself provides an edge over other existing techniques as fingerprints can even be lifted from low-reflecting surfaces. The proposed system is very economical and compact.},
 author = {{Satish Kumar Dubey} and {Dalip Singh Mehta} and {Arun Anand} and {Chandra Shakher}},
 year = {2008},
 title = {Simultaneous topography and tomography of latent fingerprints using full-field swept-source optical coherence tomography},
 pages = {015307},
 volume = {10},
 number = {1},
 journal = {Journal of Optics A: Pure and Applied Optics},
 doi = {10.1088/1464-4258/10/01/015307},
 file = {Satish Kumar Dubey, Dalip Singh Mehta et al 2008 - Simultaneous topography and tomography:Attachments/Satish Kumar Dubey, Dalip Singh Mehta et al 2008 - Simultaneous topography and tomography.pdf:application/pdf}
}


@article{Schippling.2015,
 author = {Schippling, Sven},
 year = {2015},
 title = {Optische Koh{\"a}renztomografie (OCT)},
 pages = {177--184},
 journal = {Multiple Sklerose 2015},
 doi = {10.1016/B978-3-437-22083-8.00013-4},
 file = {OCT{\_}Anleitung:Attachments/OCT{\_}Anleitung.pdf:application/pdf}
}


@article{Shanker.1996,
 author = {Shanker, M. and Hu, M. Y. and Hung, M. S.},
 year = {1996},
 title = {Effect of data standardization on neural network training},
 pages = {385--397},
 journal = {Omega 24},
 doi = {10.1016/0305-0483(96)00010-2},
 file = {1-s2.0-0305048396000102-main:Attachments/1-s2.0-0305048396000102-main.pdf:application/pdf}
}


@article{Shipitko.2018,
 author = {Shipitko, Oleg and Grigoryev, Anton},
 year = {2018},
 title = {Gaussian filtering for FPGA based image processing with High-Level Synthesis tools},
 journal = {IITP RAS, Bolshoy Karetnyy per. 19}
}


@article{Simard.2003,
 author = {Simard, Patrice Y. and Steinkraus, David and Platt, John C. and others},
 year = {2003},
 title = {Best practices for convolutional neural networks applied to visual document analysis},
 journal = {Seventh International Conference on Document, Icda 3},
 file = {Simard, Steinkraus et al 2003 - Best practices for convolutional neural:Attachments/Simard, Steinkraus et al 2003 - Best practices for convolutional neural.pdf:application/pdf}
}


@inproceedings{Simard.2003b,
 author = {Simard, P. Y. and Steinkraus, D. and Platt, J. C.},
 title = {Best practices for convolutional neural networks applied to visual document analysis},
 pages = {958--963},
 publisher = {{IEEE Comput. Soc}},
 isbn = {0-7695-1960-1},
 booktitle = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings},
 year = {2003},
 doi = {10.1109/ICDAR.2003.1227801},
 file = {icdar03:Attachments/icdar03.pdf:application/pdf}
}


@article{Simonyan.942014,
 abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
 author = {Simonyan, Karen and Zisserman, Andrew},
 year = {2015},
 title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
 url = {http://arxiv.org/pdf/1409.1556v6},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 journal = {ICLR},
 file = {1409.1556:Attachments/1409.1556.pdf:application/pdf}
}


@article{Skaik.2008,
 abstract = {Ophthalmology and vision science},
 author = {Skaik, Younis Abed El-Wahhab},
 year = {2008},
 title = {Understanding and using sensitivity, specificity and predictive values},
 keywords = {Eye Diseases/diagnosis;Humans;Predictive Value of Tests;Reproducibility of Results;Sensitivity and Specificity},
 pages = {341; author reply 341},
 journal = {Indian journal of ophthalmology 56},
 doi = {10.4103/0301-4738.41424},
 file = {IndianJOphthalmol-56-45:Attachments/IndianJOphthalmol-56-45.pdf:application/pdf}
}


@misc{Skillmon.2018,
 author = {Skillmon},
 year = {2018},
 title = {K-Fold cross-validation figure using TikZ or table},
 url = {https://tex.stackexchange.com/questions/429451/k-fold-cross-validation-figure-using-tikz-or-table},
 urldate = {14.04.2022}
}


@proceedings{Springer.2018,
 year = {2018},
 title = {Asian Conference on Computer Vision},
 institution = {Springer}
}


@article{Srivastava.7222015,
 abstract = {Theoretical and empirical evidence indicates that the depth of neural networks is crucial for their success. However, training becomes more difficult as depth increases, and training of very deep networks remains an open problem. Here we introduce a new architecture designed to overcome this. Our so-called highway networks allow unimpeded information flow across many layers on information highways. They are inspired by Long Short-Term Memory recurrent networks and use adaptive gating units to regulate the information flow. Even with hundreds of layers, highway networks can be trained directly through simple gradient descent. This enables the study of extremely deep and efficient architectures.},
 author = {Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"u}rgen},
 year = {2015},
 title = {Training Very Deep Networks},
 url = {http://arxiv.org/pdf/1507.06228v2},
 keywords = {Computer Science - Learning;Computer Science - Neural and Evolutionary Computing},
 journal = {Advances in Neural Information Processing Systems 28},
 file = {1507.06228:Attachments/1507.06228.pdf:application/pdf}
}


@article{Stifter.2007,
 abstract = {Optical coherence tomography (OCT), a method for depth-resolved imaging within turbid media based on the concept of low-coherence interferometry, rapidly evolved in the recent years with the development of a multitude of new functionalities and modalities. Biomedical research and diagnostics have been up to now the main driving forces for the reported applications and progress in OCT. The characteristics of OCT, precisely the ability to provide high-resolution images in a contact-free way, render this technique also attractive for a broad spectrum of research topics and applications outside the biomedical field. Consequently, a variety of novel applications for OCT and developments for the method itself have started to emerge. In this review we will give a detailed overview of the so far presented OCT-based methods and applications, ranging from dimensional metrology, material research and non-destructive testing, over art diagnostics, botany, microfluidics to data storage and security applications, and include new data from a study on penetration depths in various polymer materials as well as on birefringence imaging of different crystalline polymer structures. Finally, advanced and related OCT techniques are presented with high potential for future applications outside the biomedical field.},
 author = {Stifter, D.},
 year = {2007},
 title = {Beyond biomedicine: a review of alternative applications and developments for optical coherence tomography},
 pages = {337--357},
 journal = {Applied Physics B 88},
 doi = {10.1007/s00340-007-2743-2},
 file = {Stifter 2007 - Beyond biomedicine:Attachments/Stifter 2007 - Beyond biomedicine.pdf:application/pdf}
}


@article{Tajbakhsh.2016,
 abstract = {Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: \emph{Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch?} To address this question, we considered 4 distinct medical imaging applications in 3 specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from 3 different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that (1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; (2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; (3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and (4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.},
 author = {Tajbakhsh, Nima and Shin, Jae Y. and Gurudu, Suryakanth R. and Hurst, R. Todd and Kendall, Christopher B. and Gotway, Michael B. and Liang, Jianming},
 year = {2016},
 title = {Convolutional Neural Networks for Medical Image Analysis: Full Training  or Fine Tuning?},
 url = {http://arxiv.org/pdf/1706.00712v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition;Computer Science - Learning},
 pages = {1299--1312},
 volume = {35},
 issn = {0278-0062},
 journal = {IEEE Transactions on Medical Imaging},
 doi = {10.1109/TMI.2016.2535302},
 file = {1706.00712:Attachments/1706.00712.pdf:application/pdf}
}


@inproceedings{Takahashi.2018,
 abstract = {Deep convolutional neural networks (CNNs) have demonstrated remarkable results in image recognition owing to their rich expression ability and numerous parameters. However, an excessive expression ability compared to the variety of training images often has a risk of overfitting. Data augmentation techniques have been proposed to address this problem as they enrich datasets by flipping, cropping, resizing, and color-translating images. They enable deep CNNs to achieve an impressive performance. In this study, we propose a new data augmentation technique called random image cropping and patching (RICAP), which randomly crops four images and patches them to construct a new training image. Hence, RICAP randomly picks up subsets of original features among the four images and discard others, enriching the variety of training images. Also, RICAP mixes the class labels of the four images and enjoys a benefit similar to label smoothing. We evaluated RICAP with current state-of-the-art CNNs (e.g., shake-shake regularization model) and achieved a new state-of-the-art test error of red2.23{\%} on CIFAR-10 among competitive data augmentation techniques such as cutout and mixup. We also confirmed that deep CNNs with RICAP achieved better results on CIFAR-100 and ImageNet than those results obtained by other techniques.},
 author = {Takahashi, Ryo and Matsubara, Takashi and Uehara, Kuniaki},
 title = {RICAP: Random Image Cropping and Patching Data Augmentation for Deep CNNs},
 url = {https://proceedings.mlr.press/v95/takahashi18a.html},
 pages = {786--798},
 volume = {95},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 editor = {Zhu, Jun and Takeuchi, Ichiro},
 booktitle = {Proceedings of The 10th Asian Conference on Machine Learning},
 year = {2018},
 file = {Takahashi, Matsubara et al 2018 - RICAP Random Image Cropping:Attachments/Takahashi, Matsubara et al 2018 - RICAP Random Image Cropping.pdf:application/pdf}
}


@article{Takahashi.2020,
 abstract = {Deep convolutional neural networks (CNNs) have achieved remarkable results in image processing tasks. However, their high expression ability risks overfitting. Consequently, data augmentation techniques have been proposed to prevent overfitting while enriching datasets. Recent CNN architectures with more parameters are rendering traditional data augmentation techniques insufficient. In this study, we propose a new data augmentation technique called random image cropping and patching (RICAP) which randomly crops four images and patches them to create a new training image. Moreover, RICAP mixes the class labels of the four images, resulting in an advantage similar to label smoothing. We evaluated RICAP with current state-of-the-art CNNs (e.g., the shake-shake regularization model) by comparison with competitive data augmentation techniques such as cutout and mixup. RICAP achieves a new state-of-the-art test error of {\$}2.19\%$ on CIFAR-10. We also confirmed that deep CNNs with RICAP achieve better results on classification tasks using CIFAR-100 and ImageNet and an image-caption retrieval task using Microsoft COCO.},
 author = {Takahashi, Ryo and Matsubara, Takashi and Uehara, Kuniaki},
 year = {2020},
 title = {Data Augmentation using Random Image Cropping and Patching for Deep CNNs},
 url = {http://arxiv.org/pdf/1811.09030v2},
 keywords = {Computer Science - Computer Vision and Pattern Recognition;Computer Science - Learning},
 pages = {2917--2931},
 volume = {30},
 number = {9},
 issn = {1051-8215},
 journal = {IEEE Transactions on Circuits and Systems for Video Technology},
 doi = {10.1109/TCSVT.2019.2935128},
 file = {1811.09030:Attachments/1811.09030.pdf:application/pdf}
}


@article{Tharwat.2021,
 author = {Tharwat, Alaa},
 year = {2021},
 title = {Classification assessment methods},
 pages = {168--192},
 volume = {17},
 number = {1},
 issn = {2210-8327},
 journal = {Applied Computing and Informatics},
 doi = {10.1016/j.aci.2018.08.003},
 file = {10-1016{\_}j-aci-2018-08-003:Attachments/10-1016{\_}j-aci-2018-08-003.pdf:application/pdf}
}


@article{Thimm.1995,
 abstract = {Proper initialization is one of the most important prerequisites for fast convergence of feed-forward neural networks like high order and multilayer perceptrons. This publication aims at determining the optimal value of the initial weight variance (or range), which is the principal parameter of random weight initialization methods for both types of neural networks.},
 author = {Thimm, G. and Fiesler, E.},
 year = {1995},
 title = {Neural network initialization},
 url = {https://doi.org/10.1007/3-540-59497-3_220},
 pages = {535--542},
 journal = {From Natural to Artificial Neural Computation, IWANN},
 file = {Thimm, Fiesler 1995 - Neural network initialization:Attachments/Thimm, Fiesler 1995 - Neural network initialization.pdf:application/pdf}
}


@misc{Thoma.2015,
 author = {Thoma, Martin},
 year = {2015},
 title = {LaTeX-examples},
 url = {https://github.com/MartinThoma/LaTeX-examples},
 address = {GitHub},
 publisher = {GitHub}
}


@misc{TorchContributors.2017,
 author = {{Torch Contributors}},
 editor = {{Torch Contributors}},
 year = {2017},
 title = {MODELS AND PRE-TRAINED WEIGHTS},
 url = {https://pytorch.org/vision/stable/models.html}
}


@article{Tsantis.2012,
 abstract = {PURPOSE

Optical coherence tomography (OCT) is a catheter-based imaging method that employs near-infrared light to produce high-resolution cross-sectional intravascular images. The authors propose a segmentation technique for automatic lumen area extraction and stent strut detection in intravascular OCT images for the purpose of quantitative analysis of neointimal hyperplasia (NIH).

METHODS

A clinical dataset of frequency-domain OCT scans of the human femoral artery was analyzed. First, a segmentation method based on the Markov random field (MRF) model was employed for lumen area identification. Second, textural and edge information derived from local intensity distribution and continuous wavelet transform (CWT) analysis were integrated to extract the inner luminal contour. Finally, the stent strut positions were detected via the introduction of each strut wavelet response across scales into a feature extraction and classification scheme in order to optimize the strut position detection.

RESULTS

The inner lumen contour and the position of stent strut were extracted with very high accuracy. Compared with manual segmentation by an expert vascular physician the automatic segmentation had an average overlap value of 0.937$\pm$0.045 for all OCT images included in the study. The strut detection accuracy had an area under the curve (AUC) value of 0.95, together with sensitivity and specificity average values of 0.91 and 0.96, respectively.

CONCLUSIONS

A robust automatic segmentation technique integrating textural and edge information for vessel lumen border extraction and strut detection in intravascular OCT images was designed and presented. The proposed algorithm may be employed for automated quantitative morphological analysis of in-stent neointimal hyperplasia.},
 author = {Tsantis, Stavros and Kagadis, George C. and Katsanos, Konstantinos and Karnabatidis, Dimitris and Bourantas, George and Nikiforidis, George C.},
 year = {2012},
 title = {Automatic vessel lumen segmentation and stent strut detection in intravascular optical coherence tomography},
 keywords = {Algorithms;Blood Vessel Prosthesis/adverse effects;Femoral Artery/pathology/surgery;Foreign Bodies/diagnosis;Humans;Hyperplasia/etiology;Image Enhancement/methods;Image Interpretation, Computer-Assisted/methods;Neointima/diagnosis/etiology;Pattern Recognition, Automated/methods;Reproducibility of Results;Sensitivity and Specificity;Stents/adverse effects;Tomography, Optical Coherence/methods},
 pages = {503--513},
 journal = {Medical physics 39},
 doi = {10.1118/1.3673067},
 file = {Medical Physics - 2011 - Tsantis - Automatic vessel lumen segmentation and stent strut detection in intravascular optical:Attachments/Medical Physics - 2011 - Tsantis - Automatic vessel lumen segmentation and stent strut detection in intravascular optical.pdf:application/pdf}
}


@misc{Twin.2021,
 author = {Twin, Alexandra},
 year = {2021},
 title = {Overfitting: What Is Overfitting?},
 url = {https://www.investopedia.com/terms/o/overfitting.asp},
 urldate = {15.04.2022}
}


@article{Ughi.2013,
 abstract = {Intravascular optical coherence tomography (IVOCT) is rapidly becoming the method of choice for the in vivo investigation of coronary artery disease. While IVOCT visualizes atherosclerotic plaques with a resolution {\textless}20m, image analysis in terms of tissue composition is currently performed by a time-consuming manual procedure based on the qualitative interpretation of image features. We illustrate an algorithm for the automated and systematic characterization of IVOCT atherosclerotic tissue. The proposed method consists in a supervised classification of image pixels according to textural features combined with the estimated value of the optical attenuation coefficient. IVOCT images of 64 plaques, from 49 in vivo IVOCT data sets, constituted the algorithm's training and testing data sets. Validation was obtained by comparing automated analysis results to the manual assessment of atherosclerotic plaques. An overall pixel-wise accuracy of 81.5{\%} with a classification feasibility of 76.5{\%} and per-class accuracy of 89.5{\%}, 72.1{\%} and 79.5{\%} for fibrotic, calcified and lipid-rich tissue respectively, was found. Moreover, measured optical properties were in agreement with previous results reported in literature. As such, an algorithm for automated tissue characterization was developed and validated using in vivo human data, suggesting that it can be applied to clinical IVOCT data. This might be an important step towards the integration of IVOCT in cardiovascular research and routine clinical practice.},
 author = {Ughi, Giovanni Jacopo and Adriaenssens, Tom and Sinnaeve, Peter and Desmet, Walter and D'hooge, Jan},
 year = {2013},
 title = {Automated tissue characterization of in vivo atherosclerotic plaques by intravascular optical coherence tomography images},
 pages = {1014--1030},
 journal = {Biomedical optics express 4},
 doi = {10.1364/BOE.4.001014},
 file = {boe-4-7-1014:Attachments/boe-4-7-1014.pdf:application/pdf}
}


@misc{user121799.2022,
 author = {user121799},
 year = {2022},
 title = {Plotting over/underfitting graph with TikZ package},
 url = {https://tex.stackexchange.com/questions/485900/plotting-over-underfitting-graph-with-tikz-package},
 urldate = {14.04.2022}
}


@misc{user194703.2019,
 author = {user194703},
 editor = {user194703},
 year = {2019},
 title = {visualizing matrix convolution},
 url = {https://tex.stackexchange.com/questions/522118/visualizing-matrix-convolution},
 urldate = {15.04.2022}
}


@misc{user30471.2020,
 author = {user30471},
 year = {2020},
 title = {Replicating a plot using tikz},
 url = {https://tex.stackexchange.com/questions/561921/replicating-a-plot-using-tikz},
 urldate = {15.04.2022}
}


@article{VaniS..2019,
 author = {Vani, S. and Madhusudhana, Rao T. V.},
 year = {2019},
 title = {An Experimental Approach towards the Performance Assessment of Various Optimizers on Convolutional Neural Network},
 pages = {331--336},
 journal = {Third International Conference on Trends in Electronics and Informatics (ICOEI)},
 doi = {10.1109/ICOEI.2019.8862686},
 file = {Vani S, Rao T V Madhusudhana 2019 - An Experimental Approach:Attachments/Vani S, Rao T V Madhusudhana 2019 - An Experimental Approach.pdf:application/pdf}
}


@article{vanRijsbergen.1979,
 author = {{van Rijsbergen}, Cornelius Joost},
 year = {1979},
 title = {Information retrieval},
 journal = {2nd. newton, ma}
}


@article{Wald.2014,
 abstract = {OBJECTIVES

The area under a receiver operating characteristic (ROC) curve (the AUC) is used as a measure of the performance of a screening or diagnostic test. We here assess the validity of the AUC.

METHODS

Assuming the test results follow Gaussian distributions in affected and unaffected individuals, standard mathematical formulae were used to describe the relationship between the detection rate (DR) (or sensitivity) and the false-positive rate (FPR) of a test with the AUC. These formulae were used to calculate the screening performance (DR for a given FPR, or FPR for a given DR) for different AUC values according to different standard deviations of the test result in affected and unaffected individuals.

RESULTS

The DR for a given FPR is strongly dependent on relative differences in the standard deviation of the test variable in affected and unaffected individuals. Consequently, two tests with the same AUC can have a different DR for the same FPR. For example, an AUC of 0.75 has a DR of 24{\%} for a 5{\%} FPR if the standard deviations are the same in affected and unaffected individuals, but 39{\%} for the same 5{\%} FPR if the standard deviation in affected individuals is 1.5 times that in unaffected individuals.

CONCLUSION

The AUC is an unreliable measure of screening performance because in practice the standard deviation of a screening or diagnostic test in affected and unaffected individuals can differ. The problem is avoided by not using AUC at all, and instead specifying DRs for given FPRs or FPRs for given DRs.},
 author = {Wald, N. J. and Bestwick, J. P.},
 year = {2014},
 title = {Is the area under an ROC curve a valid measure of the performance of a screening or diagnostic test?},
 keywords = {Area Under Curve;AUC;diagnostic test;Diagnostic Tests, Routine/methods/standards;False Positive Reactions;Humans;Mass Screening/methods;Models, Theoretical;Normal Distribution;Reproducibility of Results;ROC Curve;screening test},
 pages = {51--56},
 volume = {21},
 number = {1},
 journal = {Journal of medical screening},
 doi = {10.1177/0969141313517497},
 file = {0969141313517497:Attachments/0969141313517497.pdf:application/pdf}
}


@article{WeiYu.2016,
 abstract = {Proceedings of the International Conference on Machine Learning 2016},
 author = {Yu, Wei and Yang, Kuiyuan and Bai, Yalong and Xiao, Tianjun and Yao, Hongxun and Rui, Yong},
 year = {2016},
 title = {Visualizing and Comparing AlexNet and VGG using Deconvolutional Layers},
 keywords = {CNN;feedback;Visualization},
 journal = {33rd International Conference on Machine Learning},
 file = {4:Attachments/4.pdf:application/pdf}
}


@article{Welzel.2001,
 abstract = {Background/aims: Optical coherence tomography (OCT) is a non-invasive technique for morphological investigation of tissue. Since its development in the late 1980s it is mainly used as a diagnostic tool in ophthalmology. For examination of a highly scattering tissue like the skin, it was necessary to modify the method. Early studies on the value of OCT for skin diagnosis gave promising results. Methods: The OCT technique is based on the principle of Michelson interferometry. The light sources used for OCT are low coherent superluminescent diodes operating at a wavelength of about 1300 nm. OCT provides two-dimensional images with a scan length of a few millimeters (mm), a resolution of about 15 \textgreek{m}m and a maximum detection depth of 1.5 mm. The image acquisition can be performed nearly in real time. The measurement is non-invasive and with no side effects. Results: The in vivo OCT images of human skin show a strong scattering from tissue with a few layers and some optical inhomogeneities. The resolution enables the visualization of architectural changes, but not of single cells. In palmoplantar skin, the thick stratum corneum is visible as a low-scattering superficial well defined layer with spiral sweat gland ducts inside. The epidermis can be distinguished from the dermis. Adnexal structures and blood vessels are low-scattering regions in the upper dermis. Skin tumors show a homogenous signal distribution. In some cases, tumor borders to healthy skin are detectable. Inflammatory skin diseases lead to changes of the OCT image, such as thickening of the epidermis and reduction of the light attenuation in the dermis. A quantification of treatment effects, such as swelling of the horny layer due to application of a moisturizer, is possible. Repeated measurements allow a monitoring of the changes over time. Conclusion: OCT is a promising new bioengineering method for investigation of skin morphology. In some cases it may be useful for diagnosis of skin diseases. Because of its non-invasive character, the technique allows monitoring of inflammatory diseases over time. An objective quantification of the efficacy and tolerance of topical treatment is also possible. Due to the high resolution and simple application, OCT is an interesting addition to other morphological techniques in dermatology.},
 author = {Welzel, Julia},
 year = {2001},
 title = {Optical coherence tomography in dermatology},
 keywords = {bioengineering method;in vivo investigation;optical coherence tomography (OCT);skin diseases},
 pages = {1--9},
 volume = {7},
 journal = {Skin Research and Technology},
 doi = {10.1034/j.1600-0846.2001.007001001.x},
 file = {Welzel 2001 - Optical coherence tomography in dermatology:Attachments/Welzel 2001 - Optical coherence tomography in dermatology.pdf:application/pdf}
}


@article{WojciechZaremba.2014,
 author = {{Wojciech Zaremba} and {Ilya Sutskever} and {Oriol Vinyals}},
 year = {2014},
 title = {Recurrent Neural Network Regularization},
 volume = {abs/1409.2329},
 journal = {CoRR},
 file = {Wojciech Zaremba, Ilya Sutskever et al 2014 - Recurrent Neural Network Regularization:Attachments/Wojciech Zaremba, Ilya Sutskever et al 2014 - Recurrent Neural Network Regularization.pdf:application/pdf}
}


@inproceedings{Wong.2016,
 abstract = {2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA);2016; ; ;10.1109/DICTA.2016.7797091},
 author = {Wong, Sebastien C. and Gatt, Adam and Stamatescu, Victor and McDonnell, Mark D.},
 title = {Understanding Data Augmentation for Classification: When to Warp?},
 pages = {1--6},
 publisher = {IEEE},
 isbn = {978-1-5090-2896-2},
 booktitle = {2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)},
 year = {2016},
 doi = {10.1109/DICTA.2016.7797091},
 file = {Understanding{\_}Data{\_}Augmentation{\_}for{\_}Classification{\_}When{\_}to{\_}Warp:Attachments/Understanding{\_}Data{\_}Augmentation{\_}for{\_}Classification{\_}When{\_}to{\_}Warp.pdf:application/pdf}
}


@article{Wu.2015,
 abstract = {Purpose

To evaluate long-term, longitudinal displacement of the optic nerve head (ONH) and anterior lamina cribrosa surfaces in glaucoma patients imaged with spectral-domain optical coherence tomography (SD OCT).

Design

Prospective study.

Participants

A total of 173 eyes of 108 subjects (88 with glaucoma and 20 normal subjects) followed for a mean of 5.3 years.

Methods

The optic disc was imaged with SD OCT at approximately 4-month intervals, and the ONH surface depth (ONHSD), anterior lamina cribrosa surface depth (ALCSD), and prelaminar tissue thickness (PTT) were measured. The reproducibility coefficients of ONHSD, ALCSD, and PTT were calculated from 2 baseline measurements of the glaucoma group. Change in ONHSD/ALCSD/PTT was confirmed when the differences between the first baseline and the latest 2 consecutive follow-up visits were greater than the corresponding reproducibility coefficient. Factors associated with ONHSD and ALCSD changes were identified with linear mixed modeling.

Main Outcome Measures

Proportion of eyes with ONHSD/ALCSD change.

Results

Within the glaucoma group, 23.9{\%} (33 eyes) had confirmed ONHSD change (15.2{\%} with posterior and 8.7{\%} with anterior displacement) and 24.6{\%} (34 eyes) had confirmed ALCSD change (12.3{\%}~with posterior and 12.3{\%} with anterior displacement). Some 9.4{\%} (13 eyes) showed a decrease in PTT, and 2.2{\%} (3 eyes) showed an increase in PTT. The specificity for detection of ONHSD/ALCSD/PTT change was 91.4{\%} (95{\%} confidence interval [CI], 77.6-97.0), 82.9{\%} (95{\%} CI, 67.3-91.9), and 94.3{\%} (95{\%} CI, 81.4-98.4), respectively. There were no significant differences in the proportion of eyes with visual field progression or history of filtration surgery between the groups with anterior and posterior displacement of ONH/anterior laminar surfaces (P $\geq$ 0.678). For each millimeter of mercury increase in the average intraocular pressure (IOP) during follow-up, the ONH and anterior laminar surfaces displaced posteriorly by 1.6 \textgreek{m}m and 2.0 \textgreek{m}m, respectively. An older age was~associated with a decrease in magnitude of posterior displacement of the ONH and anterior laminar surfaces (P $\leq$ 0.009).

Conclusions

The ONH and anterior laminar surfaces displaced not only posteriorly but also anteriorly (with reference to Bruch's membrane opening) in a significant portion of glaucoma patients. The magnitude of change was related to age and the averaged IOP during follow-up.},
 author = {Wu, Zhongheng and Xu, Guihua and Weinreb, Robert N. and Yu, Marco and Leung, Christopher K. S.},
 year = {2015},
 title = {Optic Nerve Head Deformation in Glaucoma: A Prospective Analysis of Optic Nerve Head Surface and Lamina Cribrosa Surface Displacement},
 url = {https://www.sciencedirect.com/science/article/pii/S0161642015001797},
 pages = {1317--1329},
 journal = {Ophthalmology 122},
 doi = {10.1016/j.ophtha.2015.02.035}
}


@article{Yabushita.2002,
 abstract = {Background--- High-resolution visualization of atherosclerotic plaque morphology may be essential for identifying coronary plaques that cause acute coronary events. Optical coherence tomography (OCT) is an intravascular imaging modality capable of providing cross-sectional images of tissue with a resolution of 10 \textgreek{m}m. To date, OCT imaging has not been investigated in sufficient detail to assess its accuracy for characterizing atherosclerotic plaques. The aim of this study was to establish objective OCT image criteria for atherosclerotic plaque characterization in vitro. Methods and Results--- OCT images of 357 (diseased) atherosclerotic arterial segments obtained at autopsy were correlated with histology. OCT image criteria for 3 types of plaque were formulated by analysis of a subset (n=50) of arterial segments. OCT images of fibrous plaques were characterized by homogeneous, signal-rich regions; fibrocalcific plaques by well-delineated, signal-poor regions with sharp borders; and lipid-rich plaques by signal-poor regions with diffuse borders. Independent validation of these criteria by 2 OCT readers for the remaining segments (n=307) demonstrated a sensitivity and specificity ranging from 71{\%} to 79{\%} and 97{\%} to 98{\%} for fibrous plaques, 95{\%} to 96{\%} and 97{\%} for fibrocalcific plaques, and 90{\%} to 94{\%} and 90{\%} to 92{\%} for lipid-rich plaques, respectively (overall agreement, \textgreek{k}=0.83 to 0.84). The interobserver and intraobserver reliabilities of OCT assessment were high (\textgreek{k} values of 0.88 and 0.91, respectively). Conclusions--- Objective OCT criteria are highly sensitive and specific for characterizing different types of atherosclerotic plaques. These results represent an important step in validating this new intravascular imaging modality and will provide a basis for the interpretation of intracoronary OCT images obtained from patients.},
 author = {Yabushita, Hiroshi and Bouma, Brett E. and Houser, Stuart L. and Aretz, H. Thomas and Jang, Ik-Kyung and Schlendorf, Kelly H. and Kauffman, Christopher R. and Shishkov, Milen and Kang, Dong-Heon and Halpern, Elkan F. and Tearney, Guillermo J.},
 year = {2002},
 title = {Characterization of Human Atherosclerosis by Optical Coherence Tomography},
 pages = {1640--1645},
 journal = {Circulation 106},
 doi = {10.1161/01.CIR.0000029927.92825.F6},
 file = {Yabushita, Bouma et al 2002 - Characterization of Human Atherosclerosis:Attachments/Yabushita, Bouma et al 2002 - Characterization of Human Atherosclerosis.pdf:application/pdf}
}


@article{Yanagihara.2020,
 abstract = {Artificial intelligence (AI)-based automated classification and segmentation of optical coherence tomography (OCT) features have become increasingly popular. However, its 3-dimensional volumetric nature has made developing an algorithm that generalizes across all patient populations and OCT devices challenging. Several recent studies have reported high diagnostic performances of AI models; however, significant methodological challenges still exist in applying these models in real-world clinical practice. Lack of large-image datasets from multiple OCT devices, nonstandardized imaging or post-processing protocols between devices, limited graphics processing unit capabilities for exploiting 3-dimensional features, and inconsistency in the reporting metrics are major hurdles in enabling AI for OCT analyses. We discuss these issues and present possible solutions.},
 author = {Yanagihara, Ryan T. and Lee, Cecilia S. and Ting, Daniel Shu Wei and Lee, Aaron Y.},
 year = {2020},
 title = {Methodological Challenges of Deep Learning in Optical Coherence Tomography for Retinal Diseases: A Review},
 keywords = {Algorithms;Artificial Intelligence;deep learning;Humans;Retinal Diseases/diagnostic imaging;Tomography, Optical Coherence},
 pages = {11},
 volume = {9},
 number = {2},
 issn = {2164-2591},
 journal = {Translational vision science {\&} technology},
 doi = {10.1167/tvst.9.2.11},
 file = {i2164-2591-225-2-1873:Attachments/i2164-2591-225-2-1873.pdf:application/pdf}
}


@article{YonghuaZhao.2000,
 abstract = {We have developed a novel phase-resolved optical coherence tomography (OCT) and optical Doppler tomography (ODT) system that uses phase information derived from a Hilbert transformation to image blood flow in human skin with fast scanning speed and high velocity sensitivity. Using the phase change between sequential scans to construct flow-velocity imaging, this technique decouples spatial resolution and velocity sensitivity in flow images and increases imaging speed by more than 2 orders of magnitude without compromising spatial resolution or velocity sensitivity. The minimum flow velocity that can be detected with an axial-line scanning speed of 400 Hz and an average phase change over eight sequential scans is as low as 10~$\backslash$textmum is maintained. Using this technique, we present what are to our knowledge the first phase-resolved OCT/ODT images of blood flow in human skin.},
 author = {{Yonghua Zhao} and {Zhongping Chen} and {Christopher Saxer} and {Shaohua Xiang} and {Johannes F. de Boer} and {J. Stuart Nelson}},
 year = {2000},
 title = {Phase-resolved optical coherence tomography and optical Doppler tomography for imaging blood flow in human skin with fast scanning speed and high velocity sensitivity},
 keywords = {biological imaging;Doppler effect;Fast Fourier transforms;Medical;optical coherence tomography;Optical Doppler tomography;Phase retrieval;Real time imaging;Tomography},
 pages = {114--116},
 volume = {25},
 number = {2},
 journal = {Opt. Lett.},
 doi = {10.1364/OL.25.000114}
}


@article{Zhao.2015,
 abstract = {Worldwide, many hundreds of thousands of stents are implanted each year to revascularize occlusions in coronary arteries. Intravascular optical coherence tomography is an important emerging imaging technique, which has the resolution and contrast necessary to quantitatively analyze stent deployment and tissue coverage following stent implantation. Automation is needed, as current, it takes up to 16 h to manually analyze hundreds of images and thousands of stent struts from a single pullback. For automated strut detection, we used image formation physics and machine learning via a Bayesian network, and 3-D knowledge of stent structure via graph search. Graph search was done on en face projections using minimum spanning tree algorithms. Depths of all struts in a pullback were simultaneously determined using graph cut. To assess the method, we employed the largest validation data set used so far, involving more than 8000 clinical images from 103 pullbacks from 72 patients. Automated strut detection achieved a 0.91$\pm$0.04 recall, and 0.84$\pm$0.08 precision. Performance was robust in images of varying quality. This method can improve the workflow for analysis of stent clinical trial data, and can potentially be used in the clinic to facilitate real-time stent analysis and visualization, aiding stent implantation.},
 author = {Zhao, Wang and Jenkins, Michael W. and Linderman, George C. and Bezerra, Hiram G. and Fujino, Yusuke and Costa, Marco A. and Wilson, David L. and Rollins, Andrew M.},
 year = {2015},
 title = {3-D Stent Detection in Intravascular OCT Using a Bayesian Network and Graph Search},
 keywords = {Bayesian methods;graph search;optical coherence tomography;stent},
 pages = {1549--1561},
 journal = {IEEE Transactions on Medical Imaging 34},
 doi = {10.1109/TMI.2015.2405341},
 file = {3-D{\_}Stent{\_}Detection{\_}in{\_}Intravascular{\_}OCT{\_}Using{\_}a{\_}Bayesian{\_}Network{\_}and{\_}Graph{\_}Search:Attachments/3-D{\_}Stent{\_}Detection{\_}in{\_}Intravascular{\_}OCT{\_}Using{\_}a{\_}Bayesian{\_}Network{\_}and{\_}Graph{\_}Search.pdf:application/pdf}
}


@proceedings{Zhu.2018,
 year = {2018},
 title = {Proceedings of The 10th Asian Conference on Machine Learning},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 editor = {Zhu, Jun and Takeuchi, Ichiro}
}


@article{Zhu.2020,
 abstract = {The Matthews Correlation Coefficient (MCC) is one of the popular measurements for classification accuracy. It has been generally regarded as a balanced measure which can be used even if the classes are of very different sizes. The study of this paper finds that this is not true. MCC deteriorates seriously when the dataset in classification are imbalanced. Experiment results and analysis show that MCC is not suitable for classification accuracy measurement on imbalanced datasets.},
 author = {Zhu, Qiuming},
 year = {2020},
 title = {On the performance of Matthews correlation coefficient (MCC) for imbalanced dataset},
 url = {https://www.sciencedirect.com/science/article/pii/S016786552030115X},
 keywords = {Classification accuracy measurement;Imbalanced dataset;Matthews correlation coefficient;Performance evaluation},
 pages = {71--80},
 volume = {136},
 issn = {01678655},
 journal = {Pattern Recognition Letters},
 doi = {10.1016/j.patrec.2020.03.030}
}


@misc{Zhu.3302017,
 abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain $X$ to a target domain $Y$ in the absence of paired examples. Our goal is to learn a mapping {\$}G: X $\backslash$rightarrow Y{\$} such that the distribution of images from {\$}G(X){\$} is indistinguishable from the distribution $Y$ using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping {\$}F: Y $\backslash$rightarrow X{\$} and introduce a cycle consistency loss to push {\$}F(G(X)) $\backslash$approx X{\$} (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
 author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
 date = {3/30/2017},
 title = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial  Networks},
 url = {http://arxiv.org/pdf/1703.10593v7},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 file = {Zhu{\_}Unpaired{\_}Image-To-Image{\_}Translation{\_}ICCV{\_}2017{\_}paper:Attachments/Zhu{\_}Unpaired{\_}Image-To-Image{\_}Translation{\_}ICCV{\_}2017{\_}paper.pdf:application/pdf}
}


